{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "class MNISTModel(pl.LightningModule):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MNISTModel, self).__init__()\n",
    "        # not the best model...\n",
    "        self.l1 = torch.nn.Linear(28 * 28, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # called with self(x)\n",
    "        return torch.relu(self.l1(x.view(x.size(0), -1)))\n",
    "\n",
    "    def training_step(self, batch, batch_nb):\n",
    "        # REQUIRED\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        tensorboard_logs = {'train_loss': loss}\n",
    "        return {'loss': loss, 'log': tensorboard_logs}\n",
    "\n",
    "    def validation_step(self, batch, batch_nb):\n",
    "        # OPTIONAL\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        return {'val_loss': F.cross_entropy(y_hat, y)}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        # OPTIONAL\n",
    "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        tensorboard_logs = {'val_loss': avg_loss}\n",
    "        return {'val_loss': avg_loss, 'log': tensorboard_logs}\n",
    "\n",
    "    def test_step(self, batch, batch_nb):\n",
    "        # OPTIONAL\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        return {'test_loss': F.cross_entropy(y_hat, y)}\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "        # OPTIONAL\n",
    "        avg_loss = torch.stack([x['test_loss'] for x in outputs]).mean()\n",
    "        logs = {'test_loss': avg_loss}\n",
    "        return {'test_loss': avg_loss, 'log': logs, 'progress_bar': logs}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # REQUIRED\n",
    "        # can return multiple optimizers and learning_rate schedulers\n",
    "        # (LBFGS it is automatically supported, no need for closure function)\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.02)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        # REQUIRED\n",
    "        return DataLoader(MNIST(os.getcwd(), train=True, download=True, transform=transforms.ToTensor()), batch_size=32)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        # OPTIONAL\n",
    "        return DataLoader(MNIST(os.getcwd(), train=True, download=True, transform=transforms.ToTensor()), batch_size=32)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        # OPTIONAL\n",
    "        return DataLoader(MNIST(os.getcwd(), train=False, download=True, transform=transforms.ToTensor()), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      ".44it/s, loss=1.462, v_num=8]\n",
      "Epoch 0:  98%|█████████▊| 3688/3750 [00:16<00:00, 219.30it/s, loss=1.462, v_num=8]\n",
      "Epoch 0: 100%|██████████| 3750/3750 [00:17<00:00, 220.59it/s, loss=1.462, v_num=8]\n",
      "Epoch 1:  50%|█████     | 1875/3750 [00:12<00:12, 150.45it/s, loss=1.469, v_num=8]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1911/3750 [00:12<00:12, 151.79it/s, loss=1.469, v_num=8]\n",
      "Epoch 1:  52%|█████▏    | 1950/3750 [00:12<00:11, 153.49it/s, loss=1.469, v_num=8]\n",
      "Epoch 1:  53%|█████▎    | 1989/3750 [00:12<00:11, 155.10it/s, loss=1.469, v_num=8]\n",
      "Epoch 1:  54%|█████▍    | 2028/3750 [00:12<00:10, 156.73it/s, loss=1.469, v_num=8]\n",
      "Epoch 1:  55%|█████▌    | 2067/3750 [00:13<00:10, 158.37it/s, loss=1.469, v_num=8]\n",
      "Epoch 1:  56%|█████▌    | 2106/3750 [00:13<00:10, 159.94it/s, loss=1.469, v_num=8]\n",
      "Validating:  13%|█▎        | 236/1875 [00:00<00:04, 333.02it/s]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2145/3750 [00:13<00:09, 161.39it/s, loss=1.469, v_num=8]\n",
      "Epoch 1:  58%|█████▊    | 2184/3750 [00:13<00:09, 162.95it/s, loss=1.469, v_num=8]\n",
      "Epoch 1:  59%|█████▉    | 2223/3750 [00:13<00:09, 164.45it/s, loss=1.469, v_num=8]\n",
      "Epoch 1:  60%|██████    | 2262/3750 [00:13<00:08, 165.96it/s, loss=1.469, v_num=8]\n",
      "Epoch 1:  61%|██████▏   | 2301/3750 [00:13<00:08, 167.36it/s, loss=1.469, v_num=8]\n",
      "Epoch 1:  62%|██████▏   | 2340/3750 [00:13<00:08, 168.83it/s, loss=1.469, v_num=8]\n",
      "Epoch 1:  63%|██████▎   | 2379/3750 [00:13<00:08, 170.16it/s, loss=1.469, v_num=8]\n",
      "Epoch 1:  64%|██████▍   | 2418/3750 [00:14<00:07, 171.40it/s, loss=1.469, v_num=8]\n",
      "Validating:  29%|██▉       | 544/1875 [00:01<00:04, 324.03it/s]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 2457/3750 [00:14<00:07, 172.63it/s, loss=1.469, v_num=8]\n",
      "Epoch 1:  67%|██████▋   | 2496/3750 [00:14<00:07, 173.94it/s, loss=1.469, v_num=8]\n",
      "Epoch 1:  68%|██████▊   | 2535/3750 [00:14<00:06, 175.20it/s, loss=1.469, v_num=8]\n",
      "Epoch 1:  69%|██████▊   | 2574/3750 [00:14<00:06, 176.52it/s, loss=1.469, v_num=8]\n",
      "Epoch 1:  70%|██████▉   | 2613/3750 [00:14<00:06, 177.75it/s, loss=1.469, v_num=8]\n",
      "Epoch 1:  71%|███████   | 2652/3750 [00:14<00:06, 179.02it/s, loss=1.469, v_num=8]\n",
      "Epoch 1:  72%|███████▏  | 2691/3750 [00:14<00:05, 180.25it/s, loss=1.469, v_num=8]\n",
      "Validating:  44%|████▎     | 817/1875 [00:02<00:03, 334.71it/s]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 2730/3750 [00:15<00:05, 181.43it/s, loss=1.469, v_num=8]\n",
      "Epoch 1:  74%|███████▍  | 2769/3750 [00:15<00:05, 182.63it/s, loss=1.469, v_num=8]\n",
      "Epoch 1:  75%|███████▍  | 2808/3750 [00:15<00:05, 183.80it/s, loss=1.469, v_num=8]\n",
      "Epoch 1:  76%|███████▌  | 2847/3750 [00:15<00:04, 184.88it/s, loss=1.469, v_num=8]\n",
      "Epoch 1:  77%|███████▋  | 2886/3750 [00:15<00:04, 186.06it/s, loss=1.469, v_num=8]\n",
      "Epoch 1:  78%|███████▊  | 2925/3750 [00:15<00:04, 187.21it/s, loss=1.469, v_num=8]\n",
      "Epoch 1:  79%|███████▉  | 2964/3750 [00:15<00:04, 188.21it/s, loss=1.469, v_num=8]\n",
      "Validating:  58%|█████▊    | 1092/1875 [00:03<00:02, 328.22it/s]\u001b[A\n",
      "Epoch 1:  80%|████████  | 3003/3750 [00:15<00:03, 189.33it/s, loss=1.469, v_num=8]\n",
      "Epoch 1:  81%|████████  | 3042/3750 [00:15<00:03, 190.42it/s, loss=1.469, v_num=8]\n",
      "Epoch 1:  82%|████████▏ | 3081/3750 [00:16<00:03, 191.59it/s, loss=1.469, v_num=8]\n",
      "Epoch 1:  83%|████████▎ | 3120/3750 [00:16<00:03, 192.63it/s, loss=1.469, v_num=8]\n",
      "Epoch 1:  84%|████████▍ | 3159/3750 [00:16<00:03, 193.66it/s, loss=1.469, v_num=8]\n",
      "Epoch 1:  85%|████████▌ | 3198/3750 [00:16<00:02, 194.67it/s, loss=1.469, v_num=8]\n",
      "Epoch 1:  86%|████████▋ | 3237/3750 [00:16<00:02, 195.72it/s, loss=1.469, v_num=8]\n",
      "Epoch 1:  87%|████████▋ | 3276/3750 [00:16<00:02, 196.73it/s, loss=1.469, v_num=8]\n",
      "Epoch 1:  88%|████████▊ | 3315/3750 [00:16<00:02, 197.72it/s, loss=1.469, v_num=8]\n",
      "Epoch 1:  89%|████████▉ | 3354/3750 [00:16<00:01, 198.66it/s, loss=1.469, v_num=8]\n",
      "Validating:  79%|███████▉  | 1480/1875 [00:04<00:01, 338.16it/s]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 3393/3750 [00:16<00:01, 199.62it/s, loss=1.469, v_num=8]\n",
      "Epoch 1:  92%|█████████▏| 3432/3750 [00:17<00:01, 200.58it/s, loss=1.469, v_num=8]\n",
      "Epoch 1:  93%|█████████▎| 3471/3750 [00:17<00:01, 201.51it/s, loss=1.469, v_num=8]\n",
      "Epoch 1:  94%|█████████▎| 3510/3750 [00:17<00:01, 202.42it/s, loss=1.469, v_num=8]\n",
      "Epoch 1:  95%|█████████▍| 3549/3750 [00:17<00:00, 203.35it/s, loss=1.469, v_num=8]\n",
      "Epoch 1:  96%|█████████▌| 3588/3750 [00:17<00:00, 204.22it/s, loss=1.469, v_num=8]\n",
      "Epoch 1:  97%|█████████▋| 3627/3750 [00:17<00:00, 205.09it/s, loss=1.469, v_num=8]\n",
      "Epoch 1:  98%|█████████▊| 3666/3750 [00:17<00:00, 205.99it/s, loss=1.469, v_num=8]\n",
      "Epoch 1:  99%|█████████▉| 3705/3750 [00:17<00:00, 206.92it/s, loss=1.469, v_num=8]\n",
      "Validating:  98%|█████████▊| 1833/1875 [00:05<00:00, 348.27it/s]\u001b[A\n",
      "Epoch 1: 100%|██████████| 3750/3750 [00:18<00:00, 207.76it/s, loss=1.469, v_num=8]\n",
      "Epoch 2:  50%|█████     | 1875/3750 [00:12<00:12, 147.60it/s, loss=1.448, v_num=8]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2:  51%|█████     | 1911/3750 [00:12<00:12, 149.02it/s, loss=1.448, v_num=8]\n",
      "Epoch 2:  52%|█████▏    | 1950/3750 [00:12<00:11, 150.63it/s, loss=1.448, v_num=8]\n",
      "Epoch 2:  53%|█████▎    | 1989/3750 [00:13<00:11, 152.27it/s, loss=1.448, v_num=8]\n",
      "Epoch 2:  54%|█████▍    | 2028/3750 [00:13<00:11, 153.88it/s, loss=1.448, v_num=8]\n",
      "Epoch 2:  55%|█████▌    | 2067/3750 [00:13<00:10, 155.51it/s, loss=1.448, v_num=8]\n",
      "Epoch 2:  56%|█████▌    | 2106/3750 [00:13<00:10, 157.09it/s, loss=1.448, v_num=8]\n",
      "Validating:  13%|█▎        | 235/1875 [00:00<00:04, 334.70it/s]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 2145/3750 [00:13<00:10, 158.43it/s, loss=1.448, v_num=8]\n",
      "Epoch 2:  58%|█████▊    | 2184/3750 [00:13<00:09, 159.49it/s, loss=1.448, v_num=8]\n",
      "Epoch 2:  59%|█████▉    | 2223/3750 [00:13<00:09, 160.94it/s, loss=1.448, v_num=8]\n",
      "Epoch 2:  60%|██████    | 2262/3750 [00:13<00:09, 162.44it/s, loss=1.448, v_num=8]\n",
      "Epoch 2:  61%|██████▏   | 2301/3750 [00:14<00:08, 163.96it/s, loss=1.448, v_num=8]\n",
      "Epoch 2:  62%|██████▏   | 2340/3750 [00:14<00:08, 165.41it/s, loss=1.448, v_num=8]\n",
      "Validating:  25%|██▍       | 468/1875 [00:01<00:04, 331.56it/s]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 2379/3750 [00:14<00:08, 166.75it/s, loss=1.448, v_num=8]\n",
      "Epoch 2:  64%|██████▍   | 2418/3750 [00:14<00:07, 168.06it/s, loss=1.448, v_num=8]\n",
      "Epoch 2:  66%|██████▌   | 2457/3750 [00:14<00:07, 169.35it/s, loss=1.448, v_num=8]\n",
      "Epoch 2:  67%|██████▋   | 2496/3750 [00:14<00:07, 170.76it/s, loss=1.448, v_num=8]\n",
      "Epoch 2:  68%|██████▊   | 2535/3750 [00:14<00:07, 172.02it/s, loss=1.448, v_num=8]\n",
      "Epoch 2:  69%|██████▊   | 2574/3750 [00:14<00:06, 173.22it/s, loss=1.448, v_num=8]\n",
      "Epoch 2:  70%|██████▉   | 2613/3750 [00:14<00:06, 174.48it/s, loss=1.448, v_num=8]\n",
      "Validating:  40%|███▉      | 741/1875 [00:02<00:03, 327.85it/s]\u001b[A\n",
      "Epoch 2:  71%|███████   | 2652/3750 [00:15<00:06, 175.68it/s, loss=1.448, v_num=8]\n",
      "Epoch 2:  72%|███████▏  | 2691/3750 [00:15<00:05, 176.90it/s, loss=1.448, v_num=8]\n",
      "Epoch 2:  73%|███████▎  | 2730/3750 [00:15<00:05, 178.12it/s, loss=1.448, v_num=8]\n",
      "Epoch 2:  74%|███████▍  | 2769/3750 [00:15<00:05, 179.30it/s, loss=1.448, v_num=8]\n",
      "Epoch 2:  75%|███████▍  | 2808/3750 [00:15<00:05, 180.43it/s, loss=1.448, v_num=8]\n",
      "Epoch 2:  76%|███████▌  | 2847/3750 [00:15<00:04, 181.57it/s, loss=1.448, v_num=8]\n",
      "Epoch 2:  77%|███████▋  | 2886/3750 [00:15<00:04, 182.66it/s, loss=1.448, v_num=8]\n",
      "Validating:  54%|█████▍    | 1013/1875 [00:03<00:02, 326.48it/s]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 2925/3750 [00:15<00:04, 183.40it/s, loss=1.448, v_num=8]\n",
      "Epoch 2:  79%|███████▉  | 2964/3750 [00:16<00:04, 184.28it/s, loss=1.448, v_num=8]\n",
      "Epoch 2:  80%|████████  | 3003/3750 [00:16<00:04, 185.00it/s, loss=1.448, v_num=8]\n",
      "Epoch 2:  81%|████████  | 3042/3750 [00:16<00:03, 186.01it/s, loss=1.448, v_num=8]\n",
      "Validating:  62%|██████▏   | 1171/1875 [00:03<00:02, 296.19it/s]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 3081/3750 [00:16<00:03, 187.01it/s, loss=1.448, v_num=8]\n",
      "Epoch 2:  83%|████████▎ | 3120/3750 [00:16<00:03, 188.03it/s, loss=1.448, v_num=8]\n",
      "Epoch 2:  84%|████████▍ | 3159/3750 [00:16<00:03, 189.04it/s, loss=1.448, v_num=8]\n",
      "Epoch 2:  85%|████████▌ | 3198/3750 [00:16<00:02, 190.03it/s, loss=1.448, v_num=8]\n",
      "Epoch 2:  86%|████████▋ | 3237/3750 [00:16<00:02, 191.04it/s, loss=1.448, v_num=8]\n",
      "Epoch 2:  87%|████████▋ | 3276/3750 [00:17<00:02, 191.96it/s, loss=1.448, v_num=8]\n",
      "Validating:  75%|███████▍  | 1405/1875 [00:04<00:01, 324.50it/s]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 3315/3750 [00:17<00:02, 192.90it/s, loss=1.448, v_num=8]\n",
      "Epoch 2:  89%|████████▉ | 3354/3750 [00:17<00:02, 193.86it/s, loss=1.448, v_num=8]\n",
      "Epoch 2:  90%|█████████ | 3393/3750 [00:17<00:01, 194.83it/s, loss=1.448, v_num=8]\n",
      "Epoch 2:  92%|█████████▏| 3432/3750 [00:17<00:01, 195.77it/s, loss=1.448, v_num=8]\n",
      "Epoch 2:  93%|█████████▎| 3471/3750 [00:17<00:01, 196.75it/s, loss=1.448, v_num=8]\n",
      "Epoch 2:  94%|█████████▎| 3510/3750 [00:17<00:01, 197.60it/s, loss=1.448, v_num=8]\n",
      "Epoch 2:  95%|█████████▍| 3549/3750 [00:17<00:01, 198.47it/s, loss=1.448, v_num=8]\n",
      "Validating:  89%|████████▉ | 1678/1875 [00:05<00:00, 332.16it/s]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 3588/3750 [00:18<00:00, 199.33it/s, loss=1.448, v_num=8]\n",
      "Epoch 2:  97%|█████████▋| 3627/3750 [00:18<00:00, 200.14it/s, loss=1.448, v_num=8]\n",
      "Epoch 2:  98%|█████████▊| 3666/3750 [00:18<00:00, 201.09it/s, loss=1.448, v_num=8]\n",
      "Epoch 2:  99%|█████████▉| 3705/3750 [00:18<00:00, 201.96it/s, loss=1.448, v_num=8]\n",
      "Epoch 2: 100%|██████████| 3750/3750 [00:18<00:00, 202.85it/s, loss=1.448, v_num=8]\n",
      "Epoch 3:  50%|█████     | 1875/3750 [00:13<00:13, 141.53it/s, loss=1.469, v_num=8]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 3:  51%|█████     | 1911/3750 [00:13<00:12, 142.75it/s, loss=1.469, v_num=8]\n",
      "Epoch 3:  52%|█████▏    | 1950/3750 [00:13<00:12, 144.14it/s, loss=1.469, v_num=8]\n",
      "Validating:   4%|▍         | 84/1875 [00:00<00:06, 276.00it/s]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 1989/3750 [00:13<00:12, 145.54it/s, loss=1.469, v_num=8]\n",
      "Epoch 3:  54%|█████▍    | 2028/3750 [00:13<00:11, 146.95it/s, loss=1.469, v_num=8]\n",
      "Epoch 3:  55%|█████▌    | 2067/3750 [00:13<00:11, 148.15it/s, loss=1.469, v_num=8]\n",
      "Validating:  10%|█         | 196/1875 [00:00<00:06, 269.44it/s]\u001b[A\n",
      "Epoch 3:  56%|█████▌    | 2106/3750 [00:14<00:11, 149.09it/s, loss=1.469, v_num=8]\n",
      "Epoch 3:  57%|█████▋    | 2145/3750 [00:14<00:10, 150.28it/s, loss=1.469, v_num=8]\n",
      "Validating:  15%|█▍        | 272/1875 [00:01<00:06, 253.57it/s]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 2184/3750 [00:14<00:10, 151.67it/s, loss=1.469, v_num=8]\n",
      "Epoch 3:  59%|█████▉    | 2223/3750 [00:14<00:09, 152.95it/s, loss=1.469, v_num=8]\n",
      "Epoch 3:  60%|██████    | 2262/3750 [00:14<00:09, 154.31it/s, loss=1.469, v_num=8]\n",
      "Epoch 3:  61%|██████▏   | 2301/3750 [00:14<00:09, 155.75it/s, loss=1.469, v_num=8]\n",
      "Validating:  23%|██▎       | 429/1875 [00:01<00:04, 303.80it/s]\u001b[A\n",
      "Epoch 3:  62%|██████▏   | 2340/3750 [00:14<00:08, 157.18it/s, loss=1.469, v_num=8]\n",
      "Epoch 3:  63%|██████▎   | 2379/3750 [00:15<00:08, 158.52it/s, loss=1.469, v_num=8]\n",
      "Epoch 3:  64%|██████▍   | 2418/3750 [00:15<00:08, 159.87it/s, loss=1.469, v_num=8]\n",
      "Epoch 3:  66%|██████▌   | 2457/3750 [00:15<00:08, 161.08it/s, loss=1.469, v_num=8]\n",
      "Epoch 3:  67%|██████▋   | 2496/3750 [00:15<00:07, 162.45it/s, loss=1.469, v_num=8]\n",
      "Epoch 3:  68%|██████▊   | 2535/3750 [00:15<00:07, 163.73it/s, loss=1.469, v_num=8]\n",
      "Validating:  35%|███▌      | 665/1875 [00:02<00:03, 325.93it/s]\u001b[A\n",
      "Epoch 3:  69%|██████▊   | 2574/3750 [00:15<00:07, 164.96it/s, loss=1.469, v_num=8]\n",
      "Epoch 3:  70%|██████▉   | 2613/3750 [00:15<00:06, 166.30it/s, loss=1.469, v_num=8]\n",
      "Epoch 3:  71%|███████   | 2652/3750 [00:15<00:06, 167.50it/s, loss=1.469, v_num=8]\n",
      "Epoch 3:  72%|███████▏  | 2691/3750 [00:15<00:06, 168.70it/s, loss=1.469, v_num=8]\n",
      "Epoch 3:  73%|███████▎  | 2730/3750 [00:16<00:06, 169.91it/s, loss=1.469, v_num=8]\n",
      "Epoch 3:  74%|███████▍  | 2769/3750 [00:16<00:05, 171.08it/s, loss=1.469, v_num=8]\n",
      "Epoch 3:  75%|███████▍  | 2808/3750 [00:16<00:05, 172.21it/s, loss=1.469, v_num=8]\n",
      "Epoch 3:  76%|███████▌  | 2847/3750 [00:16<00:05, 173.35it/s, loss=1.469, v_num=8]\n",
      "Validating:  52%|█████▏    | 973/1875 [00:03<00:02, 328.93it/s]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 2886/3750 [00:16<00:04, 174.36it/s, loss=1.469, v_num=8]\n",
      "Epoch 3:  78%|███████▊  | 2925/3750 [00:16<00:04, 175.48it/s, loss=1.469, v_num=8]\n",
      "Epoch 3:  79%|███████▉  | 2964/3750 [00:16<00:04, 176.62it/s, loss=1.469, v_num=8]\n",
      "Epoch 3:  80%|████████  | 3003/3750 [00:16<00:04, 177.67it/s, loss=1.469, v_num=8]\n",
      "Epoch 3:  81%|████████  | 3042/3750 [00:17<00:03, 178.77it/s, loss=1.469, v_num=8]\n",
      "Epoch 3:  82%|████████▏ | 3081/3750 [00:17<00:03, 179.84it/s, loss=1.469, v_num=8]\n",
      "Validating:  65%|██████▍   | 1210/1875 [00:03<00:01, 332.71it/s]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 3120/3750 [00:17<00:03, 180.80it/s, loss=1.469, v_num=8]\n",
      "Epoch 3:  84%|████████▍ | 3159/3750 [00:17<00:03, 181.78it/s, loss=1.469, v_num=8]\n",
      "Epoch 3:  85%|████████▌ | 3198/3750 [00:17<00:03, 182.69it/s, loss=1.469, v_num=8]\n",
      "Epoch 3:  86%|████████▋ | 3237/3750 [00:17<00:02, 183.53it/s, loss=1.469, v_num=8]\n",
      "Epoch 3:  87%|████████▋ | 3276/3750 [00:17<00:02, 184.46it/s, loss=1.469, v_num=8]\n",
      "Validating:  75%|███████▌  | 1407/1875 [00:04<00:01, 312.90it/s]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 3315/3750 [00:17<00:02, 185.37it/s, loss=1.469, v_num=8]\n",
      "Epoch 3:  89%|████████▉ | 3354/3750 [00:17<00:02, 186.35it/s, loss=1.469, v_num=8]\n",
      "Epoch 3:  90%|█████████ | 3393/3750 [00:18<00:01, 187.27it/s, loss=1.469, v_num=8]\n",
      "Epoch 3:  92%|█████████▏| 3432/3750 [00:18<00:01, 188.12it/s, loss=1.469, v_num=8]\n",
      "Epoch 3:  93%|█████████▎| 3471/3750 [00:18<00:01, 188.87it/s, loss=1.469, v_num=8]\n",
      "Epoch 3:  94%|█████████▎| 3510/3750 [00:18<00:01, 189.77it/s, loss=1.469, v_num=8]\n",
      "Validating:  87%|████████▋ | 1639/1875 [00:05<00:00, 315.39it/s]\u001b[A\n",
      "Epoch 3:  95%|█████████▍| 3549/3750 [00:18<00:01, 190.61it/s, loss=1.469, v_num=8]\n",
      "Epoch 3:  96%|█████████▌| 3588/3750 [00:18<00:00, 191.49it/s, loss=1.469, v_num=8]\n",
      "Epoch 3:  97%|█████████▋| 3627/3750 [00:18<00:00, 192.40it/s, loss=1.469, v_num=8]\n",
      "Epoch 3:  98%|█████████▊| 3666/3750 [00:18<00:00, 193.27it/s, loss=1.469, v_num=8]\n",
      "Epoch 3:  99%|█████████▉| 3705/3750 [00:19<00:00, 194.10it/s, loss=1.469, v_num=8]\n",
      "Epoch 3: 100%|█████████▉| 3744/3750 [00:19<00:00, 194.88it/s, loss=1.469, v_num=8]\n",
      "Epoch 3: 100%|██████████| 3750/3750 [00:19<00:00, 194.91it/s, loss=1.469, v_num=8]\n",
      "Epoch 4:  50%|█████     | 1875/3750 [00:12<00:12, 144.53it/s, loss=1.444, v_num=8]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 4:  51%|█████     | 1911/3750 [00:13<00:12, 145.52it/s, loss=1.444, v_num=8]\n",
      "Validating:   3%|▎         | 47/1875 [00:00<00:07, 234.02it/s]\u001b[A\n",
      "Epoch 4:  52%|█████▏    | 1950/3750 [00:13<00:12, 146.37it/s, loss=1.444, v_num=8]\n",
      "Validating:   5%|▍         | 87/1875 [00:00<00:08, 204.60it/s]\u001b[A\n",
      "Epoch 4:  53%|█████▎    | 1989/3750 [00:13<00:11, 146.96it/s, loss=1.444, v_num=8]\n",
      "Validating:   7%|▋         | 126/1875 [00:00<00:08, 198.36it/s]\u001b[A\n",
      "Epoch 4:  54%|█████▍    | 2028/3750 [00:13<00:11, 147.73it/s, loss=1.444, v_num=8]\n",
      "Validating:   9%|▉         | 170/1875 [00:00<00:08, 207.58it/s]\u001b[A\n",
      "Epoch 4:  55%|█████▌    | 2067/3750 [00:13<00:11, 148.61it/s, loss=1.444, v_num=8]\n",
      "Epoch 4:  56%|█████▌    | 2106/3750 [00:14<00:10, 149.71it/s, loss=1.444, v_num=8]\n",
      "Validating:  13%|█▎        | 240/1875 [00:01<00:07, 223.67it/s]\u001b[A\n",
      "Epoch 4:  57%|█████▋    | 2145/3750 [00:14<00:10, 150.79it/s, loss=1.444, v_num=8]\n",
      "Epoch 4:  58%|█████▊    | 2184/3750 [00:14<00:10, 151.74it/s, loss=1.444, v_num=8]\n",
      "Validating:  17%|█▋        | 315/1875 [00:01<00:06, 230.74it/s]\u001b[A\n",
      "Epoch 4:  59%|█████▉    | 2223/3750 [00:14<00:09, 152.73it/s, loss=1.444, v_num=8]\n",
      "Epoch 4:  60%|██████    | 2262/3750 [00:14<00:09, 153.74it/s, loss=1.444, v_num=8]\n",
      "Validating:  21%|██        | 390/1875 [00:01<00:06, 239.30it/s]\u001b[A\n",
      "Epoch 4:  61%|██████▏   | 2301/3750 [00:14<00:09, 154.75it/s, loss=1.444, v_num=8]\n",
      "Epoch 4:  62%|██████▏   | 2340/3750 [00:15<00:09, 155.69it/s, loss=1.444, v_num=8]\n",
      "Validating:  25%|██▍       | 467/1875 [00:02<00:05, 241.41it/s]\u001b[A\n",
      "Epoch 4:  63%|██████▎   | 2379/3750 [00:15<00:08, 156.60it/s, loss=1.444, v_num=8]\n",
      "Validating:  28%|██▊       | 518/1875 [00:02<00:05, 244.41it/s]\u001b[A\n",
      "Epoch 4:  64%|██████▍   | 2418/3750 [00:15<00:08, 157.42it/s, loss=1.444, v_num=8]\n",
      "Epoch 4:  66%|██████▌   | 2457/3750 [00:15<00:08, 158.38it/s, loss=1.444, v_num=8]\n",
      "Validating:  32%|███▏      | 595/1875 [00:02<00:05, 245.18it/s]\u001b[A\n",
      "Epoch 4:  67%|██████▋   | 2496/3750 [00:15<00:07, 159.31it/s, loss=1.444, v_num=8]\n",
      "Epoch 4:  68%|██████▊   | 2535/3750 [00:15<00:07, 160.15it/s, loss=1.444, v_num=8]\n",
      "Validating:  36%|███▌      | 673/1875 [00:02<00:04, 242.34it/s]\u001b[A\n",
      "Epoch 4:  69%|██████▊   | 2574/3750 [00:15<00:07, 161.00it/s, loss=1.444, v_num=8]\n",
      "Epoch 4:  70%|██████▉   | 2613/3750 [00:16<00:07, 161.86it/s, loss=1.444, v_num=8]\n",
      "Validating:  40%|████      | 750/1875 [00:03<00:04, 245.58it/s]\u001b[A\n",
      "Epoch 4:  71%|███████   | 2652/3750 [00:16<00:06, 162.70it/s, loss=1.444, v_num=8]\n",
      "Epoch 4:  72%|███████▏  | 2691/3750 [00:16<00:06, 163.58it/s, loss=1.444, v_num=8]\n",
      "Validating:  44%|████▍     | 828/1875 [00:03<00:04, 251.45it/s]\u001b[A\n",
      "Epoch 4:  73%|███████▎  | 2730/3750 [00:16<00:06, 164.39it/s, loss=1.444, v_num=8]\n",
      "Epoch 4:  74%|███████▍  | 2769/3750 [00:16<00:05, 165.23it/s, loss=1.444, v_num=8]\n",
      "Validating:  48%|████▊     | 906/1875 [00:03<00:03, 252.76it/s]\u001b[A\n",
      "Epoch 4:  75%|███████▍  | 2808/3750 [00:16<00:05, 166.01it/s, loss=1.444, v_num=8]\n",
      "Epoch 4:  76%|███████▌  | 2847/3750 [00:17<00:05, 166.73it/s, loss=1.444, v_num=8]\n",
      "Validating:  52%|█████▏    | 983/1875 [00:04<00:03, 246.33it/s]\u001b[A\n",
      "Epoch 4:  77%|███████▋  | 2886/3750 [00:17<00:05, 167.32it/s, loss=1.444, v_num=8]\n",
      "Epoch 4:  78%|███████▊  | 2925/3750 [00:17<00:04, 168.00it/s, loss=1.444, v_num=8]\n",
      "Validating:  56%|█████▋    | 1057/1875 [00:04<00:03, 235.99it/s]\u001b[A\n",
      "Epoch 4:  79%|███████▉  | 2964/3750 [00:17<00:04, 168.55it/s, loss=1.444, v_num=8]\n",
      "Epoch 4:  80%|████████  | 3003/3750 [00:17<00:04, 169.14it/s, loss=1.444, v_num=8]\n",
      "Validating:  60%|██████    | 1129/1875 [00:04<00:03, 228.89it/s]\u001b[A\n",
      "Epoch 4:  81%|████████  | 3042/3750 [00:17<00:04, 169.68it/s, loss=1.444, v_num=8]\n",
      "Validating:  63%|██████▎   | 1177/1875 [00:04<00:03, 229.25it/s]\u001b[A\n",
      "Epoch 4:  82%|████████▏ | 3081/3750 [00:18<00:03, 170.22it/s, loss=1.444, v_num=8]\n",
      "Epoch 4:  83%|████████▎ | 3120/3750 [00:18<00:03, 170.81it/s, loss=1.444, v_num=8]\n",
      "Validating:  67%|██████▋   | 1248/1875 [00:05<00:02, 226.88it/s]\u001b[A\n",
      "Epoch 4:  84%|████████▍ | 3159/3750 [00:18<00:03, 171.16it/s, loss=1.444, v_num=8]\n",
      "Validating:  69%|██████▉   | 1294/1875 [00:05<00:02, 212.91it/s]\u001b[A\n",
      "Epoch 4:  85%|████████▌ | 3198/3750 [00:18<00:03, 171.52it/s, loss=1.444, v_num=8]\n",
      "Validating:  71%|███████▏  | 1338/1875 [00:05<00:02, 211.64it/s]\u001b[A\n",
      "Epoch 4:  86%|████████▋ | 3237/3750 [00:18<00:02, 171.91it/s, loss=1.444, v_num=8]\n",
      "Epoch 4:  87%|████████▋ | 3276/3750 [00:18<00:02, 172.53it/s, loss=1.444, v_num=8]\n",
      "Validating:  75%|███████▌  | 1409/1875 [00:06<00:02, 226.38it/s]\u001b[A\n",
      "Epoch 4:  88%|████████▊ | 3315/3750 [00:19<00:02, 173.13it/s, loss=1.444, v_num=8]\n",
      "Epoch 4:  89%|████████▉ | 3354/3750 [00:19<00:02, 173.82it/s, loss=1.444, v_num=8]\n",
      "Validating:  79%|███████▉  | 1487/1875 [00:06<00:01, 245.04it/s]\u001b[A\n",
      "Epoch 4:  90%|█████████ | 3393/3750 [00:19<00:02, 174.47it/s, loss=1.444, v_num=8]\n",
      "Epoch 4:  92%|█████████▏| 3432/3750 [00:19<00:01, 175.12it/s, loss=1.444, v_num=8]\n",
      "Validating:  84%|████████▎ | 1567/1875 [00:06<00:01, 251.56it/s]\u001b[A\n",
      "Epoch 4:  93%|█████████▎| 3471/3750 [00:19<00:01, 175.81it/s, loss=1.444, v_num=8]\n",
      "Epoch 4:  94%|█████████▎| 3510/3750 [00:19<00:01, 176.55it/s, loss=1.444, v_num=8]\n",
      "Epoch 4:  95%|█████████▍| 3549/3750 [00:20<00:01, 177.28it/s, loss=1.444, v_num=8]\n",
      "Validating:  90%|████████▉ | 1682/1875 [00:07<00:00, 272.09it/s]\u001b[A\n",
      "Epoch 4:  96%|█████████▌| 3588/3750 [00:20<00:00, 177.98it/s, loss=1.444, v_num=8]\n",
      "Epoch 4:  97%|█████████▋| 3627/3750 [00:20<00:00, 178.71it/s, loss=1.444, v_num=8]\n",
      "Epoch 4:  98%|█████████▊| 3666/3750 [00:20<00:00, 179.34it/s, loss=1.444, v_num=8]\n",
      "Validating:  96%|█████████▌| 1798/1875 [00:07<00:00, 271.67it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▉| 3705/3750 [00:20<00:00, 179.96it/s, loss=1.444, v_num=8]\n",
      "Epoch 4: 100%|██████████| 3750/3750 [00:20<00:00, 180.62it/s, loss=1.444, v_num=8]\n",
      "Epoch 4: 100%|██████████| 3750/3750 [00:20<00:00, 180.57it/s, loss=1.444, v_num=8]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "mnist_model = MNISTModel()\n",
    "   \n",
    "# most basic trainer, uses good defaults (1 gpu)\n",
    "trainer = pl.Trainer(gpus=1,max_epochs=5)    \n",
    "trainer.fit(mnist_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Testing:  90%|█████████ | 282/313 [00:00<00:00, 320.76it/s]--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_loss': tensor(1.5283, device='cuda:0')}\n",
      "--------------------------------------------------------------------------------\n",
      "Testing: 100%|██████████| 313/313 [00:01<00:00, 310.21it/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'test_loss': 1.528316617012024}]"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}