{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn  # All neural network modules, nn.Linear, nn.Conv2d, BatchNorm, Loss functions\n",
    "import torch.optim as optim  # For all Optimization algorithms, SGD, Adam, etc.\n",
    "import torch.nn.functional as F  # All functions that don't have any parameters\n",
    "from torch.utils.data import (\n",
    "    DataLoader,\n",
    ")  # Gives easier dataset managment and creates mini batches\n",
    "from torchvision.datasets import MNIST  # Has standard datasets we can import in a nice way\n",
    "import torchvision.transforms as transforms  # Transformations we can perform on our dataset\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import os\n",
    "\n",
    "in_channel = 1\n",
    "num_classes = 10\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "num_epochs = 5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple CNN\n",
    "class CNN(pl.LightningModule):\n",
    "    def __init__(self, in_channels=1, num_classes=10):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=1,\n",
    "            out_channels=8,\n",
    "            kernel_size=(3, 3),\n",
    "            stride=(1, 1),\n",
    "            padding=(1, 1),\n",
    "        )\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=8,\n",
    "            out_channels=16,\n",
    "            kernel_size=(3, 3),\n",
    "            stride=(1, 1),\n",
    "            padding=(1, 1),\n",
    "        )\n",
    "        self.fc1 = nn.Linear(16 * 7 * 7, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def training_step(self,batch,batcj_idx):\n",
    "        data,targets = batch\n",
    "        scores = self(data)\n",
    "        loss = F.cross_entropy(scores, targets)\n",
    "        tensorboard_logs = {'train_loss': loss}\n",
    "        return {'loss': loss, 'log': tensorboard_logs}\n",
    "\n",
    "    def validation_step(self, batch, batch_nb):\n",
    "        # OPTIONAL\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        return {'val_loss': F.cross_entropy(y_hat, y)}\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        # OPTIONAL\n",
    "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        tensorboard_logs = {'val_loss': avg_loss}\n",
    "        return {'val_loss': avg_loss, 'log': tensorboard_logs}\n",
    "\n",
    "    def test_step(self, batch, batch_nb):\n",
    "        # OPTIONAL\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        return {'test_loss': F.cross_entropy(y_hat, y)}\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "        # OPTIONAL\n",
    "        avg_loss = torch.stack([x['test_loss'] for x in outputs]).mean()\n",
    "        logs = {'test_loss': avg_loss}\n",
    "        return {'test_loss': avg_loss, 'log': logs, 'progress_bar': logs}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # REQUIRED\n",
    "        # can return multiple optimizers and learning_rate schedulers\n",
    "        # (LBFGS it is automatically supported, no need for closure function)\n",
    "        return optim.Adam(self.parameters(), lr=learning_rate)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        # REQUIRED\n",
    "        return DataLoader(MNIST(os.getcwd(), train=True, download=True, transform=transforms.ToTensor()), batch_size=32)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        # OPTIONAL\n",
    "        return DataLoader(MNIST(os.getcwd(), train=True, download=True, transform=transforms.ToTensor()), batch_size=32)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        # OPTIONAL\n",
    "        return DataLoader(MNIST(os.getcwd(), train=False, download=True, transform=transforms.ToTensor()), batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "7.94it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 3680/3750 [00:25<00:00, 141.80it/s, loss=0.143, v_num=13]\n",
      "Epoch 1:  99%|█████████▉| 3712/3750 [00:26<00:00, 142.27it/s, loss=0.143, v_num=13]\n",
      "Epoch 1: 100%|█████████▉| 3744/3750 [00:26<00:00, 142.70it/s, loss=0.143, v_num=13]\n",
      "Epoch 1: 100%|██████████| 3750/3750 [00:26<00:00, 142.68it/s, loss=0.143, v_num=13]\n",
      "Epoch 2:  50%|█████     | 1875/3750 [00:21<00:21, 85.62it/s, loss=0.110, v_num=13]\n",
      "Epoch 2:  50%|█████     | 1888/3750 [00:21<00:21, 85.99it/s, loss=0.110, v_num=13]\n",
      "Epoch 2:  51%|█████     | 1920/3750 [00:22<00:21, 86.97it/s, loss=0.110, v_num=13]\n",
      "Epoch 2:  52%|█████▏    | 1952/3750 [00:22<00:20, 87.94it/s, loss=0.110, v_num=13]\n",
      "Validating:   4%|▍         | 80/1875 [00:00<00:06, 261.09it/s]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 1984/3750 [00:22<00:19, 88.88it/s, loss=0.110, v_num=13]\n",
      "Epoch 2:  54%|█████▍    | 2016/3750 [00:22<00:19, 89.80it/s, loss=0.110, v_num=13]\n",
      "Epoch 2:  55%|█████▍    | 2048/3750 [00:22<00:18, 90.68it/s, loss=0.110, v_num=13]\n",
      "Epoch 2:  55%|█████▌    | 2080/3750 [00:22<00:18, 91.61it/s, loss=0.110, v_num=13]\n",
      "Validating:  11%|█         | 209/1875 [00:00<00:06, 251.86it/s]\u001b[A\n",
      "Epoch 2:  56%|█████▋    | 2112/3750 [00:22<00:17, 92.51it/s, loss=0.110, v_num=13]\n",
      "Epoch 2:  57%|█████▋    | 2144/3750 [00:22<00:17, 93.41it/s, loss=0.110, v_num=13]\n",
      "Epoch 2:  58%|█████▊    | 2176/3750 [00:23<00:16, 94.30it/s, loss=0.110, v_num=13]\n",
      "Epoch 2:  59%|█████▉    | 2208/3750 [00:23<00:16, 95.18it/s, loss=0.110, v_num=13]\n",
      "Epoch 2:  60%|█████▉    | 2240/3750 [00:23<00:15, 96.06it/s, loss=0.110, v_num=13]\n",
      "Validating:  20%|█▉        | 368/1875 [00:01<00:05, 258.71it/s]\u001b[A\n",
      "Epoch 2:  61%|██████    | 2272/3750 [00:23<00:15, 96.90it/s, loss=0.110, v_num=13]\n",
      "Epoch 2:  61%|██████▏   | 2304/3750 [00:23<00:14, 97.74it/s, loss=0.110, v_num=13]\n",
      "Epoch 2:  62%|██████▏   | 2336/3750 [00:23<00:14, 98.59it/s, loss=0.110, v_num=13]\n",
      "Epoch 2:  63%|██████▎   | 2368/3750 [00:23<00:13, 99.44it/s, loss=0.110, v_num=13]\n",
      "Validating:  27%|██▋       | 499/1875 [00:01<00:05, 259.37it/s]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 2400/3750 [00:23<00:13, 100.24it/s, loss=0.110, v_num=13]\n",
      "Epoch 2:  65%|██████▍   | 2432/3750 [00:24<00:13, 101.03it/s, loss=0.110, v_num=13]\n",
      "Epoch 2:  66%|██████▌   | 2464/3750 [00:24<00:12, 101.82it/s, loss=0.110, v_num=13]\n",
      "Epoch 2:  67%|██████▋   | 2496/3750 [00:24<00:12, 102.64it/s, loss=0.110, v_num=13]\n",
      "Epoch 2:  67%|██████▋   | 2528/3750 [00:24<00:11, 103.43it/s, loss=0.110, v_num=13]\n",
      "Validating:  35%|███▍      | 656/1875 [00:02<00:04, 256.78it/s]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 2560/3750 [00:24<00:11, 104.22it/s, loss=0.110, v_num=13]\n",
      "Epoch 2:  69%|██████▉   | 2592/3750 [00:24<00:11, 105.02it/s, loss=0.110, v_num=13]\n",
      "Epoch 2:  70%|██████▉   | 2624/3750 [00:24<00:10, 105.76it/s, loss=0.110, v_num=13]\n",
      "Epoch 2:  71%|███████   | 2656/3750 [00:24<00:10, 106.53it/s, loss=0.110, v_num=13]\n",
      "Epoch 2:  72%|███████▏  | 2688/3750 [00:25<00:09, 107.24it/s, loss=0.110, v_num=13]\n",
      "Validating:  44%|████▎     | 817/1875 [00:03<00:04, 249.07it/s]\u001b[A\n",
      "Epoch 2:  73%|███████▎  | 2720/3750 [00:25<00:09, 107.95it/s, loss=0.110, v_num=13]\n",
      "Epoch 2:  73%|███████▎  | 2752/3750 [00:25<00:09, 108.70it/s, loss=0.110, v_num=13]\n",
      "Epoch 2:  74%|███████▍  | 2784/3750 [00:25<00:08, 109.43it/s, loss=0.110, v_num=13]\n",
      "Epoch 2:  75%|███████▌  | 2816/3750 [00:25<00:08, 110.16it/s, loss=0.110, v_num=13]\n",
      "Epoch 2:  76%|███████▌  | 2848/3750 [00:25<00:08, 110.84it/s, loss=0.110, v_num=13]\n",
      "Validating:  52%|█████▏    | 974/1875 [00:03<00:03, 251.36it/s]\u001b[A\n",
      "Epoch 2:  77%|███████▋  | 2880/3750 [00:25<00:07, 111.51it/s, loss=0.110, v_num=13]\n",
      "Epoch 2:  78%|███████▊  | 2912/3750 [00:25<00:07, 112.16it/s, loss=0.110, v_num=13]\n",
      "Epoch 2:  79%|███████▊  | 2944/3750 [00:26<00:07, 112.83it/s, loss=0.110, v_num=13]\n",
      "Validating:  57%|█████▋    | 1075/1875 [00:04<00:03, 244.09it/s]\u001b[A\n",
      "Epoch 2:  79%|███████▉  | 2976/3750 [00:26<00:06, 113.50it/s, loss=0.110, v_num=13]\n",
      "Epoch 2:  80%|████████  | 3008/3750 [00:26<00:06, 114.12it/s, loss=0.110, v_num=13]\n",
      "Epoch 2:  81%|████████  | 3040/3750 [00:26<00:06, 114.79it/s, loss=0.110, v_num=13]\n",
      "Epoch 2:  82%|████████▏ | 3072/3750 [00:26<00:05, 115.45it/s, loss=0.110, v_num=13]\n",
      "Validating:  64%|██████▍   | 1202/1875 [00:04<00:02, 247.01it/s]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 3104/3750 [00:26<00:05, 116.02it/s, loss=0.110, v_num=13]\n",
      "Epoch 2:  84%|████████▎ | 3136/3750 [00:26<00:05, 116.64it/s, loss=0.110, v_num=13]\n",
      "Epoch 2:  84%|████████▍ | 3168/3750 [00:27<00:04, 117.22it/s, loss=0.110, v_num=13]\n",
      "Epoch 2:  85%|████████▌ | 3200/3750 [00:27<00:04, 117.87it/s, loss=0.110, v_num=13]\n",
      "Validating:  71%|███████   | 1329/1875 [00:05<00:02, 243.56it/s]\u001b[A\n",
      "Epoch 2:  86%|████████▌ | 3232/3750 [00:27<00:04, 118.50it/s, loss=0.110, v_num=13]\n",
      "Epoch 2:  87%|████████▋ | 3264/3750 [00:27<00:04, 119.14it/s, loss=0.110, v_num=13]\n",
      "Epoch 2:  88%|████████▊ | 3296/3750 [00:27<00:03, 119.76it/s, loss=0.110, v_num=13]\n",
      "Epoch 2:  89%|████████▊ | 3328/3750 [00:27<00:03, 120.34it/s, loss=0.110, v_num=13]\n",
      "Epoch 2:  90%|████████▉ | 3360/3750 [00:27<00:03, 120.97it/s, loss=0.110, v_num=13]\n",
      "Validating:  79%|███████▉  | 1487/1875 [00:05<00:01, 251.02it/s]\u001b[A\n",
      "Epoch 2:  90%|█████████ | 3392/3750 [00:27<00:02, 121.58it/s, loss=0.110, v_num=13]\n",
      "Epoch 2:  91%|█████████▏| 3424/3750 [00:28<00:02, 122.21it/s, loss=0.110, v_num=13]\n",
      "Epoch 2:  92%|█████████▏| 3456/3750 [00:28<00:02, 122.82it/s, loss=0.110, v_num=13]\n",
      "Epoch 2:  93%|█████████▎| 3488/3750 [00:28<00:02, 123.44it/s, loss=0.110, v_num=13]\n",
      "Epoch 2:  94%|█████████▍| 3520/3750 [00:28<00:01, 124.05it/s, loss=0.110, v_num=13]\n",
      "Epoch 2:  95%|█████████▍| 3552/3750 [00:28<00:01, 124.67it/s, loss=0.110, v_num=13]\n",
      "Validating:  89%|████████▉ | 1678/1875 [00:06<00:00, 267.98it/s]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 3584/3750 [00:28<00:01, 125.24it/s, loss=0.110, v_num=13]\n",
      "Epoch 2:  96%|█████████▋| 3616/3750 [00:28<00:01, 125.79it/s, loss=0.110, v_num=13]\n",
      "Epoch 2:  97%|█████████▋| 3648/3750 [00:28<00:00, 126.35it/s, loss=0.110, v_num=13]\n",
      "Epoch 2:  98%|█████████▊| 3680/3750 [00:28<00:00, 126.93it/s, loss=0.110, v_num=13]\n",
      "Epoch 2:  99%|█████████▉| 3712/3750 [00:29<00:00, 127.47it/s, loss=0.110, v_num=13]\n",
      "Validating:  98%|█████████▊| 1840/1875 [00:07<00:00, 254.01it/s]\u001b[A\n",
      "Epoch 2: 100%|██████████| 3750/3750 [00:29<00:00, 128.03it/s, loss=0.110, v_num=13]\n",
      "Epoch 3:  50%|█████     | 1875/3750 [00:19<00:19, 96.08it/s, loss=0.085, v_num=13]\n",
      "Epoch 3:  50%|█████     | 1888/3750 [00:19<00:19, 96.46it/s, loss=0.085, v_num=13]\n",
      "Epoch 3:  51%|█████     | 1920/3750 [00:19<00:18, 97.42it/s, loss=0.085, v_num=13]\n",
      "Validating:   3%|▎         | 50/1875 [00:00<00:07, 240.38it/s]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 1952/3750 [00:19<00:18, 98.36it/s, loss=0.085, v_num=13]\n",
      "Epoch 3:  53%|█████▎    | 1984/3750 [00:19<00:17, 99.23it/s, loss=0.085, v_num=13]\n",
      "Epoch 3:  54%|█████▍    | 2016/3750 [00:20<00:17, 100.15it/s, loss=0.085, v_num=13]\n",
      "Validating:   8%|▊         | 142/1875 [00:00<00:07, 227.57it/s]\u001b[A\n",
      "Epoch 3:  55%|█████▍    | 2048/3750 [00:20<00:16, 101.03it/s, loss=0.085, v_num=13]\n",
      "Epoch 3:  55%|█████▌    | 2080/3750 [00:20<00:16, 101.96it/s, loss=0.085, v_num=13]\n",
      "Epoch 3:  56%|█████▋    | 2112/3750 [00:20<00:15, 102.89it/s, loss=0.085, v_num=13]\n",
      "Validating:  13%|█▎        | 240/1875 [00:01<00:06, 240.65it/s]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 2144/3750 [00:20<00:15, 103.81it/s, loss=0.085, v_num=13]\n",
      "Epoch 3:  58%|█████▊    | 2176/3750 [00:20<00:15, 104.64it/s, loss=0.085, v_num=13]\n",
      "Epoch 3:  59%|█████▉    | 2208/3750 [00:20<00:14, 105.57it/s, loss=0.085, v_num=13]\n",
      "Epoch 3:  60%|█████▉    | 2240/3750 [00:21<00:14, 106.46it/s, loss=0.085, v_num=13]\n",
      "Validating:  20%|█▉        | 369/1875 [00:01<00:06, 249.37it/s]\u001b[A\n",
      "Epoch 3:  61%|██████    | 2272/3750 [00:21<00:13, 107.31it/s, loss=0.085, v_num=13]\n",
      "Epoch 3:  61%|██████▏   | 2304/3750 [00:21<00:13, 108.19it/s, loss=0.085, v_num=13]\n",
      "Epoch 3:  62%|██████▏   | 2336/3750 [00:21<00:12, 109.02it/s, loss=0.085, v_num=13]\n",
      "Epoch 3:  63%|██████▎   | 2368/3750 [00:21<00:12, 109.86it/s, loss=0.085, v_num=13]\n",
      "Epoch 3:  64%|██████▍   | 2400/3750 [00:21<00:12, 110.73it/s, loss=0.085, v_num=13]\n",
      "Validating:  28%|██▊       | 526/1875 [00:02<00:05, 253.56it/s]\u001b[A\n",
      "Epoch 3:  65%|██████▍   | 2432/3750 [00:21<00:11, 111.56it/s, loss=0.085, v_num=13]\n",
      "Epoch 3:  66%|██████▌   | 2464/3750 [00:21<00:11, 112.38it/s, loss=0.085, v_num=13]\n",
      "Epoch 3:  67%|██████▋   | 2496/3750 [00:22<00:11, 113.12it/s, loss=0.085, v_num=13]\n",
      "Epoch 3:  67%|██████▋   | 2528/3750 [00:22<00:10, 113.88it/s, loss=0.085, v_num=13]\n",
      "Validating:  35%|███▍      | 656/1875 [00:02<00:05, 242.08it/s]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 2560/3750 [00:22<00:10, 114.64it/s, loss=0.085, v_num=13]\n",
      "Epoch 3:  69%|██████▉   | 2592/3750 [00:22<00:10, 115.39it/s, loss=0.085, v_num=13]\n",
      "Epoch 3:  70%|██████▉   | 2624/3750 [00:22<00:09, 116.17it/s, loss=0.085, v_num=13]\n",
      "Epoch 3:  71%|███████   | 2656/3750 [00:22<00:09, 116.95it/s, loss=0.085, v_num=13]\n",
      "Validating:  42%|████▏     | 784/1875 [00:03<00:04, 251.53it/s]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 2688/3750 [00:22<00:09, 117.70it/s, loss=0.085, v_num=13]\n",
      "Epoch 3:  73%|███████▎  | 2720/3750 [00:22<00:08, 118.44it/s, loss=0.085, v_num=13]\n",
      "Epoch 3:  73%|███████▎  | 2752/3750 [00:23<00:08, 119.18it/s, loss=0.085, v_num=13]\n",
      "Epoch 3:  74%|███████▍  | 2784/3750 [00:23<00:08, 119.84it/s, loss=0.085, v_num=13]\n",
      "Validating:  49%|████▉     | 915/1875 [00:03<00:03, 243.32it/s]\u001b[A\n",
      "Epoch 3:  75%|███████▌  | 2816/3750 [00:23<00:07, 120.57it/s, loss=0.085, v_num=13]\n",
      "Epoch 3:  76%|███████▌  | 2848/3750 [00:23<00:07, 121.31it/s, loss=0.085, v_num=13]\n",
      "Epoch 3:  77%|███████▋  | 2880/3750 [00:23<00:07, 122.03it/s, loss=0.085, v_num=13]\n",
      "Epoch 3:  78%|███████▊  | 2912/3750 [00:23<00:06, 122.76it/s, loss=0.085, v_num=13]\n",
      "Epoch 3:  79%|███████▊  | 2944/3750 [00:23<00:06, 123.47it/s, loss=0.085, v_num=13]\n",
      "Validating:  57%|█████▋    | 1074/1875 [00:04<00:03, 257.90it/s]\u001b[A\n",
      "Epoch 3:  79%|███████▉  | 2976/3750 [00:23<00:06, 124.10it/s, loss=0.085, v_num=13]\n",
      "Epoch 3:  80%|████████  | 3008/3750 [00:24<00:05, 124.81it/s, loss=0.085, v_num=13]\n",
      "Epoch 3:  81%|████████  | 3040/3750 [00:24<00:05, 125.50it/s, loss=0.085, v_num=13]\n",
      "Epoch 3:  82%|████████▏ | 3072/3750 [00:24<00:05, 126.18it/s, loss=0.085, v_num=13]\n",
      "Epoch 3:  83%|████████▎ | 3104/3750 [00:24<00:05, 126.85it/s, loss=0.085, v_num=13]\n",
      "Validating:  66%|██████▌   | 1232/1875 [00:04<00:02, 256.70it/s]\u001b[A\n",
      "Epoch 3:  84%|████████▎ | 3136/3750 [00:24<00:04, 127.48it/s, loss=0.085, v_num=13]\n",
      "Epoch 3:  84%|████████▍ | 3168/3750 [00:24<00:04, 128.15it/s, loss=0.085, v_num=13]\n",
      "Epoch 3:  85%|████████▌ | 3200/3750 [00:24<00:04, 128.82it/s, loss=0.085, v_num=13]\n",
      "Epoch 3:  86%|████████▌ | 3232/3750 [00:24<00:04, 129.41it/s, loss=0.085, v_num=13]\n",
      "Epoch 3:  87%|████████▋ | 3264/3750 [00:25<00:03, 130.08it/s, loss=0.085, v_num=13]\n",
      "Validating:  74%|███████▍  | 1393/1875 [00:05<00:01, 257.60it/s]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 3296/3750 [00:25<00:03, 130.72it/s, loss=0.085, v_num=13]\n",
      "Epoch 3:  89%|████████▊ | 3328/3750 [00:25<00:03, 131.34it/s, loss=0.085, v_num=13]\n",
      "Epoch 3:  90%|████████▉ | 3360/3750 [00:25<00:02, 131.98it/s, loss=0.085, v_num=13]\n",
      "Epoch 3:  90%|█████████ | 3392/3750 [00:25<00:02, 132.46it/s, loss=0.085, v_num=13]\n",
      "Epoch 3:  91%|█████████▏| 3424/3750 [00:25<00:02, 133.04it/s, loss=0.085, v_num=13]\n",
      "Validating:  83%|████████▎ | 1551/1875 [00:06<00:01, 244.78it/s]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 3456/3750 [00:25<00:02, 133.66it/s, loss=0.085, v_num=13]\n",
      "Epoch 3:  93%|█████████▎| 3488/3750 [00:25<00:01, 134.24it/s, loss=0.085, v_num=13]\n",
      "Epoch 3:  94%|█████████▍| 3520/3750 [00:26<00:01, 134.75it/s, loss=0.085, v_num=13]\n",
      "Epoch 3:  95%|█████████▍| 3552/3750 [00:26<00:01, 135.21it/s, loss=0.085, v_num=13]\n",
      "Validating:  90%|████████▉ | 1682/1875 [00:06<00:00, 231.28it/s]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 3584/3750 [00:26<00:01, 135.64it/s, loss=0.085, v_num=13]\n",
      "Epoch 3:  96%|█████████▋| 3616/3750 [00:26<00:00, 136.05it/s, loss=0.085, v_num=13]\n",
      "Epoch 3:  97%|█████████▋| 3648/3750 [00:26<00:00, 136.44it/s, loss=0.085, v_num=13]\n",
      "Validating:  95%|█████████▍| 1774/1875 [00:07<00:00, 208.45it/s]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 3680/3750 [00:26<00:00, 136.77it/s, loss=0.085, v_num=13]\n",
      "Validating:  97%|█████████▋| 1816/1875 [00:07<00:00, 198.53it/s]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 3712/3750 [00:27<00:00, 137.03it/s, loss=0.085, v_num=13]\n",
      "Epoch 3: 100%|█████████▉| 3744/3750 [00:27<00:00, 137.24it/s, loss=0.085, v_num=13]\n",
      "Epoch 3: 100%|██████████| 3750/3750 [00:27<00:00, 137.16it/s, loss=0.085, v_num=13]\n",
      "Epoch 4:  50%|█████     | 1875/3750 [00:28<00:28, 65.41it/s, loss=0.073, v_num=13]\n",
      "Epoch 4:  50%|█████     | 1888/3750 [00:28<00:28, 65.67it/s, loss=0.073, v_num=13]\n",
      "Validating:   1%|          | 17/1875 [00:00<00:11, 166.66it/s]\u001b[A\n",
      "Epoch 4:  51%|█████     | 1920/3750 [00:28<00:27, 66.32it/s, loss=0.073, v_num=13]\n",
      "Validating:   3%|▎         | 50/1875 [00:00<00:11, 163.80it/s]\u001b[A\n",
      "Epoch 4:  52%|█████▏    | 1952/3750 [00:29<00:26, 66.97it/s, loss=0.073, v_num=13]\n",
      "Validating:   4%|▍         | 84/1875 [00:00<00:10, 163.62it/s]\u001b[A\n",
      "Epoch 4:  53%|█████▎    | 1984/3750 [00:29<00:26, 67.62it/s, loss=0.073, v_num=13]\n",
      "Validating:   6%|▋         | 118/1875 [00:00<00:10, 165.79it/s]\u001b[A\n",
      "Epoch 4:  54%|█████▍    | 2016/3750 [00:29<00:25, 68.27it/s, loss=0.073, v_num=13]\n",
      "Validating:   8%|▊         | 152/1875 [00:00<00:10, 164.77it/s]\u001b[A\n",
      "Epoch 4:  55%|█████▍    | 2048/3750 [00:29<00:24, 68.83it/s, loss=0.073, v_num=13]\n",
      "Validating:  10%|▉         | 184/1875 [00:01<00:11, 153.39it/s]\u001b[A\n",
      "Epoch 4:  55%|█████▌    | 2080/3750 [00:29<00:24, 69.42it/s, loss=0.073, v_num=13]\n",
      "Validating:  12%|█▏        | 217/1875 [00:01<00:11, 150.58it/s]\u001b[A\n",
      "Epoch 4:  56%|█████▋    | 2112/3750 [00:30<00:23, 69.98it/s, loss=0.073, v_num=13]\n",
      "Validating:  13%|█▎        | 249/1875 [00:01<00:10, 148.66it/s]\u001b[A\n",
      "Epoch 4:  57%|█████▋    | 2144/3750 [00:30<00:22, 70.54it/s, loss=0.073, v_num=13]\n",
      "Validating:  15%|█▍        | 281/1875 [00:01<00:10, 152.27it/s]\u001b[A\n",
      "Epoch 4:  58%|█████▊    | 2176/3750 [00:30<00:22, 71.13it/s, loss=0.073, v_num=13]\n",
      "Validating:  17%|█▋        | 315/1875 [00:02<00:09, 158.85it/s]\u001b[A\n",
      "Epoch 4:  59%|█████▉    | 2208/3750 [00:30<00:21, 71.74it/s, loss=0.073, v_num=13]\n",
      "Epoch 4:  60%|█████▉    | 2240/3750 [00:30<00:20, 72.32it/s, loss=0.073, v_num=13]\n",
      "Validating:  20%|█▉        | 368/1875 [00:02<00:09, 164.15it/s]\u001b[A\n",
      "Epoch 4:  61%|██████    | 2272/3750 [00:31<00:20, 72.94it/s, loss=0.073, v_num=13]\n",
      "Validating:  22%|██▏       | 406/1875 [00:02<00:08, 173.62it/s]\u001b[A\n",
      "Epoch 4:  61%|██████▏   | 2304/3750 [00:31<00:19, 73.55it/s, loss=0.073, v_num=13]\n",
      "Epoch 4:  62%|██████▏   | 2336/3750 [00:31<00:19, 74.15it/s, loss=0.073, v_num=13]\n",
      "Validating:  25%|██▍       | 463/1875 [00:02<00:07, 177.00it/s]\u001b[A\n",
      "Epoch 4:  63%|██████▎   | 2368/3750 [00:31<00:18, 74.76it/s, loss=0.073, v_num=13]\n",
      "Validating:  27%|██▋       | 502/1875 [00:03<00:07, 183.30it/s]\u001b[A\n",
      "Epoch 4:  64%|██████▍   | 2400/3750 [00:31<00:17, 75.37it/s, loss=0.073, v_num=13]\n",
      "Epoch 4:  65%|██████▍   | 2432/3750 [00:32<00:17, 75.96it/s, loss=0.073, v_num=13]\n",
      "Validating:  30%|██▉       | 561/1875 [00:03<00:07, 183.15it/s]\u001b[A\n",
      "Epoch 4:  66%|██████▌   | 2464/3750 [00:32<00:16, 76.58it/s, loss=0.073, v_num=13]\n",
      "Epoch 4:  67%|██████▋   | 2496/3750 [00:32<00:16, 77.19it/s, loss=0.073, v_num=13]\n",
      "Validating:  33%|███▎      | 622/1875 [00:03<00:06, 193.16it/s]\u001b[A\n",
      "Epoch 4:  67%|██████▋   | 2528/3750 [00:32<00:15, 77.79it/s, loss=0.073, v_num=13]\n",
      "Validating:  35%|███▌      | 663/1875 [00:03<00:06, 196.59it/s]\u001b[A\n",
      "Epoch 4:  68%|██████▊   | 2560/3750 [00:32<00:15, 78.35it/s, loss=0.073, v_num=13]\n",
      "Epoch 4:  69%|██████▉   | 2592/3750 [00:32<00:14, 78.95it/s, loss=0.073, v_num=13]\n",
      "Validating:  39%|███▊      | 724/1875 [00:04<00:05, 195.00it/s]\u001b[A\n",
      "Epoch 4:  70%|██████▉   | 2624/3750 [00:32<00:14, 79.54it/s, loss=0.073, v_num=13]\n",
      "Epoch 4:  71%|███████   | 2656/3750 [00:33<00:13, 80.12it/s, loss=0.073, v_num=13]\n",
      "Validating:  42%|████▏     | 785/1875 [00:04<00:05, 197.50it/s]\u001b[A\n",
      "Epoch 4:  72%|███████▏  | 2688/3750 [00:33<00:13, 80.68it/s, loss=0.073, v_num=13]\n",
      "Epoch 4:  73%|███████▎  | 2720/3750 [00:33<00:12, 81.26it/s, loss=0.073, v_num=13]\n",
      "Validating:  45%|████▌     | 847/1875 [00:04<00:05, 197.62it/s]\u001b[A\n",
      "Epoch 4:  73%|███████▎  | 2752/3750 [00:33<00:12, 81.84it/s, loss=0.073, v_num=13]\n",
      "Epoch 4:  74%|███████▍  | 2784/3750 [00:33<00:11, 82.42it/s, loss=0.073, v_num=13]\n",
      "Validating:  49%|████▊     | 912/1875 [00:05<00:04, 204.42it/s]\u001b[A\n",
      "Epoch 4:  75%|███████▌  | 2816/3750 [00:33<00:11, 82.97it/s, loss=0.073, v_num=13]\n",
      "Epoch 4:  76%|███████▌  | 2848/3750 [00:34<00:10, 83.53it/s, loss=0.073, v_num=13]\n",
      "Validating:  52%|█████▏    | 975/1875 [00:05<00:04, 202.35it/s]\u001b[A\n",
      "Epoch 4:  77%|███████▋  | 2880/3750 [00:34<00:10, 84.06it/s, loss=0.073, v_num=13]\n",
      "Epoch 4:  78%|███████▊  | 2912/3750 [00:34<00:09, 84.62it/s, loss=0.073, v_num=13]\n",
      "Validating:  55%|█████▌    | 1038/1875 [00:05<00:04, 203.62it/s]\u001b[A\n",
      "Epoch 4:  79%|███████▊  | 2944/3750 [00:34<00:09, 85.17it/s, loss=0.073, v_num=13]\n",
      "Epoch 4:  79%|███████▉  | 2976/3750 [00:34<00:09, 85.66it/s, loss=0.073, v_num=13]\n",
      "Validating:  59%|█████▉    | 1102/1875 [00:06<00:04, 193.15it/s]\u001b[A\n",
      "Epoch 4:  80%|████████  | 3008/3750 [00:34<00:08, 86.16it/s, loss=0.073, v_num=13]\n",
      "Validating:  61%|██████    | 1142/1875 [00:06<00:03, 189.43it/s]\u001b[A\n",
      "Epoch 4:  81%|████████  | 3040/3750 [00:35<00:08, 86.62it/s, loss=0.073, v_num=13]\n",
      "Epoch 4:  82%|████████▏ | 3072/3750 [00:35<00:07, 87.07it/s, loss=0.073, v_num=13]\n",
      "Validating:  64%|██████▍   | 1200/1875 [00:06<00:03, 177.43it/s]\u001b[A\n",
      "Epoch 4:  83%|████████▎ | 3104/3750 [00:35<00:07, 87.49it/s, loss=0.073, v_num=13]\n",
      "Validating:  66%|██████▌   | 1236/1875 [00:06<00:03, 168.79it/s]\u001b[A\n",
      "Epoch 4:  84%|████████▎ | 3136/3750 [00:35<00:06, 87.93it/s, loss=0.073, v_num=13]\n",
      "Validating:  68%|██████▊   | 1273/1875 [00:07<00:03, 174.01it/s]\u001b[A\n",
      "Epoch 4:  84%|████████▍ | 3168/3750 [00:35<00:06, 88.38it/s, loss=0.073, v_num=13]\n",
      "Epoch 4:  85%|████████▌ | 3200/3750 [00:36<00:06, 88.80it/s, loss=0.073, v_num=13]\n",
      "Validating:  71%|███████   | 1327/1875 [00:07<00:03, 168.34it/s]\u001b[A\n",
      "Epoch 4:  86%|████████▌ | 3232/3750 [00:36<00:05, 89.26it/s, loss=0.073, v_num=13]\n",
      "Validating:  73%|███████▎  | 1365/1875 [00:07<00:02, 177.04it/s]\u001b[A\n",
      "Epoch 4:  87%|████████▋ | 3264/3750 [00:36<00:05, 89.71it/s, loss=0.073, v_num=13]\n",
      "Epoch 4:  88%|████████▊ | 3296/3750 [00:36<00:05, 90.19it/s, loss=0.073, v_num=13]\n",
      "Validating:  76%|███████▌  | 1423/1875 [00:07<00:02, 185.60it/s]\u001b[A\n",
      "Epoch 4:  89%|████████▊ | 3328/3750 [00:36<00:04, 90.65it/s, loss=0.073, v_num=13]\n",
      "Validating:  78%|███████▊  | 1462/1875 [00:08<00:02, 188.64it/s]\u001b[A\n",
      "Epoch 4:  90%|████████▉ | 3360/3750 [00:36<00:04, 91.11it/s, loss=0.073, v_num=13]\n",
      "Epoch 4:  90%|█████████ | 3392/3750 [00:37<00:03, 91.59it/s, loss=0.073, v_num=13]\n",
      "Validating:  81%|████████  | 1523/1875 [00:08<00:01, 191.34it/s]\u001b[A\n",
      "Epoch 4:  91%|█████████▏| 3424/3750 [00:37<00:03, 92.03it/s, loss=0.073, v_num=13]\n",
      "Epoch 4:  92%|█████████▏| 3456/3750 [00:37<00:03, 92.49it/s, loss=0.073, v_num=13]\n",
      "Validating:  84%|████████▍ | 1583/1875 [00:08<00:01, 195.94it/s]\u001b[A\n",
      "Epoch 4:  93%|█████████▎| 3488/3750 [00:37<00:02, 92.91it/s, loss=0.073, v_num=13]\n",
      "Validating:  87%|████████▋ | 1623/1875 [00:08<00:01, 189.81it/s]\u001b[A\n",
      "Epoch 4:  94%|█████████▍| 3520/3750 [00:37<00:02, 93.36it/s, loss=0.073, v_num=13]\n",
      "Epoch 4:  95%|█████████▍| 3552/3750 [00:37<00:02, 93.83it/s, loss=0.073, v_num=13]\n",
      "Validating:  90%|████████▉ | 1685/1875 [00:09<00:00, 196.43it/s]\u001b[A\n",
      "Epoch 4:  96%|█████████▌| 3584/3750 [00:38<00:01, 94.28it/s, loss=0.073, v_num=13]\n",
      "Epoch 4:  96%|█████████▋| 3616/3750 [00:38<00:01, 94.74it/s, loss=0.073, v_num=13]\n",
      "Validating:  93%|█████████▎| 1749/1875 [00:09<00:00, 203.31it/s]\u001b[A\n",
      "Epoch 4:  97%|█████████▋| 3648/3750 [00:38<00:01, 95.19it/s, loss=0.073, v_num=13]\n",
      "Epoch 4:  98%|█████████▊| 3680/3750 [00:38<00:00, 95.65it/s, loss=0.073, v_num=13]\n",
      "Validating:  97%|█████████▋| 1813/1875 [00:09<00:00, 206.10it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▉| 3712/3750 [00:38<00:00, 96.09it/s, loss=0.073, v_num=13]\n",
      "Epoch 4: 100%|██████████| 3750/3750 [00:38<00:00, 96.58it/s, loss=0.073, v_num=13]\n",
      "Epoch 4: 100%|██████████| 3750/3750 [00:38<00:00, 96.57it/s, loss=0.073, v_num=13]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "mnist_model = CNN()\n",
    "   \n",
    "# most basic trainer, uses good defaults (1 gpu)\n",
    "trainer = pl.Trainer(gpus=1,max_epochs=5)    \n",
    "trainer.fit(mnist_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Testing:  94%|█████████▍| 294/313 [00:01<00:00, 217.63it/s]--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_loss': tensor(0.0639, device='cuda:0')}\n",
      "--------------------------------------------------------------------------------\n",
      "Testing: 100%|██████████| 313/313 [00:01<00:00, 218.28it/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'test_loss': 0.063896045088768}]"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}