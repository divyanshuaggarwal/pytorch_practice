{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Field \n",
    "from torchtext.datasets import IMDB\n",
    "\n",
    "text_field = Field(sequential=True, include_lengths=True, fix_length=200)\n",
    "label_field = Field(sequential=False)\n",
    "\n",
    "\n",
    "train, test = IMDB.splits(text_field, label_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import FastText\n",
    "\n",
    "text_field.build_vocab(train, vectors=FastText('simple'))\n",
    "label_field.build_vocab(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import BucketIterator\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "batch_size = 32\n",
    "\n",
    "train_iter, test_iter = BucketIterator.splits(\n",
    "    (train, test), \n",
    "    batch_size=batch_size, \n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.core.lightning import LightningModule\n",
    "\n",
    "class classifier(LightningModule):\n",
    "    def __init__(self, embedding, lstm_input_size=300, lstm_hidden_size=100, output_size=3):\n",
    "        super().__init__()\n",
    "        self.embedding = embedding\n",
    "        self.lstm = nn.LSTM(lstm_input_size, lstm_hidden_size)\n",
    "        self.lin = nn.Linear(lstm_hidden_size, output_size)\n",
    "        self.loss_function = nn.CrossEntropyLoss()\n",
    "    \n",
    "    def forward(self, X: torch.Tensor):\n",
    "        # need to be permuted because by default X is batch first\n",
    "        x = self.embedding[X].to(self.device).permute(1, 0, 2)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = F.elu(x.permute(1, 0, 2))\n",
    "        x = self.lin(x)\n",
    "        x = x.sum(dim=1)\n",
    "        return x\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch.text[0].T, batch.label\n",
    "        y_hat = self(x)\n",
    "        loss = self.loss_function(y_hat, y)\n",
    "        return dict(\n",
    "            loss=loss,\n",
    "            log=dict(\n",
    "                train_loss=loss\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return Adam(self.parameters(), lr=0.01)\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return train_iter\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch.text[0].T, batch.label\n",
    "        y_hat = self(x)\n",
    "        loss = self.loss_function(y_hat, y)\n",
    "        return dict(\n",
    "            test_loss=loss,\n",
    "            log=dict(\n",
    "                test_loss=loss\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    def test_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['test_loss'] for x in outputs]).mean()\n",
    "        tensorboard_logs = dict(\n",
    "            test_loss=avg_loss\n",
    "        )\n",
    "        return dict(\n",
    "            avg_test_loss=avg_loss, \n",
    "            log=tensorboard_logs\n",
    "        )\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return test_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_batch = next(iter(train_iter))\n",
    "model(sample_batch.text[0].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "model = MyModel(text_field.vocab.vectors)\n",
    "logger = TensorBoardLogger('tb_logs', name='my_model')\n",
    "trainer = Trainer(\n",
    "    gpus=1, \n",
    "    logger=logger,\n",
    "    max_epochs=10\n",
    ")\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}