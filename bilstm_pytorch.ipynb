{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn  # All neural network modules, nn.Linear, nn.Conv2d, BatchNorm, Loss functions\n",
    "import torch.optim as optim  # For all Optimization algorithms, SGD, Adam, etc.\n",
    "import torch.nn.functional as F  # All functions that don't have any parameters\n",
    "from torch.utils.data import (\n",
    "    DataLoader,\n",
    ")  # Gives easier dataset managment and creates mini batches\n",
    "import torchvision.datasets as datasets  # Has standard datasets we can import in a nice way\n",
    "import torchvision.transforms as transforms  # Transformations we can perform on our dataset\n",
    "\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "input_size = 28\n",
    "sequence_length = 28\n",
    "num_layers = 2\n",
    "hidden_size = 256\n",
    "num_classes = 10\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "num_epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BRNN(pl.LightningModule):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(BRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size, hidden_size, num_layers, batch_first=True, bidirectional=True\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size * 2, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(self.device)\n",
    "        c0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(self.device)\n",
    "\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "\n",
    "        return out\n",
    "    def prepare_data(self):\n",
    "        self.train_dataset = datasets.MNIST(\n",
    "    root=\"dataset/\", train=True, transform=transforms.ToTensor(), download=True\n",
    ")\n",
    "\n",
    "        self.test_dataset = datasets.MNIST(\n",
    "    root=\"dataset/\", train=False, transform=transforms.ToTensor(), download=True\n",
    ")   \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(dataset=self.train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self.train_dataloader()\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(dataset=self.test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr=learning_rate)\n",
    "\n",
    "    def training_step(self, batch, batch_nb):\n",
    "        # REQUIRED\n",
    "        x, y = batch\n",
    "        x = x.squeeze(1)\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        tensorboard_logs = {'train_loss': loss}\n",
    "        return {'loss': loss, 'log': tensorboard_logs}\n",
    "    \n",
    "    def validation_step(self,batch,batch_idx):\n",
    "        x,y = batch\n",
    "        x = x.squeeze(1)\n",
    "        y_hat = model(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        return {'val_loss': F.cross_entropy(y_hat, y)}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        # OPTIONAL\n",
    "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        tensorboard_logs = {'val_loss': avg_loss}\n",
    "        return {'val_loss': avg_loss, 'log': tensorboard_logs}\n",
    "    \n",
    "    def test_step(self, batch, batch_nb):\n",
    "        # OPTIONAL\n",
    "        x, y = batch\n",
    "        x = x.squeeze(1)\n",
    "        y_hat = self(x)\n",
    "        return {'test_loss': F.cross_entropy(y_hat, y)}\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "        # OPTIONAL\n",
    "        avg_loss = torch.stack([x['test_loss'] for x in outputs]).mean()\n",
    "        logs = {'test_loss': avg_loss}\n",
    "        return {'test_loss': avg_loss, 'log': logs, 'progress_bar': logs}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "17it/s]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 1539/1876 [01:17<00:17, 19.74it/s, loss=0.060, v_num=29]\n",
      "Epoch 3:  83%|████████▎ | 1548/1876 [01:18<00:16, 19.82it/s, loss=0.060, v_num=29]\n",
      "Validating:  65%|██████▌   | 613/938 [00:13<00:05, 56.47it/s]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 1557/1876 [01:18<00:16, 19.89it/s, loss=0.060, v_num=29]\n",
      "Epoch 3:  83%|████████▎ | 1566/1876 [01:18<00:15, 19.97it/s, loss=0.060, v_num=29]\n",
      "Validating:  67%|██████▋   | 631/938 [00:14<00:05, 57.17it/s]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 1575/1876 [01:18<00:15, 20.04it/s, loss=0.060, v_num=29]\n",
      "Epoch 3:  84%|████████▍ | 1584/1876 [01:18<00:14, 20.12it/s, loss=0.060, v_num=29]\n",
      "Validating:  69%|██████▉   | 649/938 [00:14<00:05, 55.54it/s]\u001b[A\n",
      "Epoch 3:  85%|████████▍ | 1593/1876 [01:18<00:14, 20.19it/s, loss=0.060, v_num=29]\n",
      "Epoch 3:  85%|████████▌ | 1602/1876 [01:19<00:13, 20.26it/s, loss=0.060, v_num=29]\n",
      "Epoch 3:  86%|████████▌ | 1611/1876 [01:19<00:13, 20.34it/s, loss=0.060, v_num=29]\n",
      "Epoch 3:  86%|████████▋ | 1620/1876 [01:19<00:12, 20.42it/s, loss=0.060, v_num=29]\n",
      "Validating:  73%|███████▎  | 683/938 [00:15<00:04, 63.73it/s]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 1629/1876 [01:19<00:12, 20.50it/s, loss=0.060, v_num=29]\n",
      "Epoch 3:  87%|████████▋ | 1638/1876 [01:19<00:11, 20.58it/s, loss=0.060, v_num=29]\n",
      "Epoch 3:  88%|████████▊ | 1647/1876 [01:19<00:11, 20.65it/s, loss=0.060, v_num=29]\n",
      "Validating:  76%|███████▌  | 711/938 [00:15<00:03, 58.85it/s]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 1656/1876 [01:19<00:10, 20.71it/s, loss=0.060, v_num=29]\n",
      "Epoch 3:  89%|████████▉ | 1665/1876 [01:20<00:10, 20.78it/s, loss=0.060, v_num=29]\n",
      "Validating:  78%|███████▊  | 729/938 [00:15<00:04, 50.86it/s]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 1674/1876 [01:20<00:09, 20.83it/s, loss=0.060, v_num=29]\n",
      "Validating:  79%|███████▉  | 740/938 [00:16<00:04, 46.23it/s]\u001b[A\n",
      "Epoch 3:  90%|████████▉ | 1683/1876 [01:20<00:09, 20.89it/s, loss=0.060, v_num=29]\n",
      "Epoch 3:  90%|█████████ | 1692/1876 [01:20<00:08, 20.94it/s, loss=0.060, v_num=29]\n",
      "Validating:  80%|████████  | 755/938 [00:16<00:04, 38.93it/s]\u001b[A\n",
      "Validating:  81%|████████  | 759/938 [00:16<00:05, 32.78it/s]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 1701/1876 [01:21<00:08, 20.96it/s, loss=0.060, v_num=29]\n",
      "Validating:  82%|████████▏ | 767/938 [00:16<00:05, 31.51it/s]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 1710/1876 [01:21<00:07, 21.00it/s, loss=0.060, v_num=29]\n",
      "Validating:  83%|████████▎ | 775/938 [00:17<00:04, 33.85it/s]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 1719/1876 [01:21<00:07, 21.05it/s, loss=0.060, v_num=29]\n",
      "Validating:  83%|████████▎ | 783/938 [00:17<00:04, 35.35it/s]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 1728/1876 [01:21<00:07, 21.08it/s, loss=0.060, v_num=29]\n",
      "Validating:  84%|████████▍ | 791/938 [00:17<00:04, 31.59it/s]\u001b[A\n",
      "Validating:  85%|████████▍ | 795/938 [00:17<00:04, 30.48it/s]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 1737/1876 [01:22<00:06, 21.11it/s, loss=0.060, v_num=29]\n",
      "Validating:  86%|████████▌ | 803/938 [00:18<00:04, 30.40it/s]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 1746/1876 [01:22<00:06, 21.15it/s, loss=0.060, v_num=29]\n",
      "Validating:  86%|████████▋ | 811/938 [00:18<00:03, 32.88it/s]\u001b[A\n",
      "Epoch 3:  94%|█████████▎| 1755/1876 [01:22<00:05, 21.20it/s, loss=0.060, v_num=29]\n",
      "Validating:  87%|████████▋ | 819/938 [00:18<00:03, 33.70it/s]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 1764/1876 [01:23<00:05, 21.22it/s, loss=0.060, v_num=29]\n",
      "Validating:  88%|████████▊ | 827/938 [00:18<00:03, 30.01it/s]\u001b[A\n",
      "Validating:  89%|████████▊ | 831/938 [00:18<00:03, 31.37it/s]\u001b[A\n",
      "Epoch 3:  95%|█████████▍| 1773/1876 [01:23<00:04, 21.26it/s, loss=0.060, v_num=29]\n",
      "Validating:  89%|████████▉ | 839/938 [00:19<00:02, 33.95it/s]\u001b[A\n",
      "Epoch 3:  95%|█████████▍| 1782/1876 [01:23<00:04, 21.31it/s, loss=0.060, v_num=29]\n",
      "Validating:  90%|█████████ | 847/938 [00:19<00:02, 34.88it/s]\u001b[A\n",
      "Epoch 3:  95%|█████████▌| 1791/1876 [01:23<00:03, 21.36it/s, loss=0.060, v_num=29]\n",
      "Validating:  91%|█████████ | 855/938 [00:19<00:02, 35.50it/s]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 1800/1876 [01:24<00:03, 21.39it/s, loss=0.060, v_num=29]\n",
      "Validating:  92%|█████████▏| 863/938 [00:19<00:02, 31.24it/s]\u001b[A\n",
      "Validating:  92%|█████████▏| 867/938 [00:20<00:02, 29.91it/s]\u001b[A\n",
      "Epoch 3:  96%|█████████▋| 1809/1876 [01:24<00:03, 21.41it/s, loss=0.060, v_num=29]\n",
      "Validating:  93%|█████████▎| 875/938 [00:20<00:02, 31.11it/s]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 1818/1876 [01:24<00:02, 21.45it/s, loss=0.060, v_num=29]\n",
      "Validating:  94%|█████████▍| 883/938 [00:20<00:01, 32.11it/s]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 1827/1876 [01:25<00:02, 21.48it/s, loss=0.060, v_num=29]\n",
      "Validating:  95%|█████████▍| 891/938 [00:20<00:01, 28.00it/s]\u001b[A\n",
      "Validating:  95%|█████████▌| 894/938 [00:20<00:01, 25.70it/s]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 1836/1876 [01:25<00:01, 21.48it/s, loss=0.060, v_num=29]\n",
      "Validating:  96%|█████████▌| 900/938 [00:21<00:01, 24.08it/s]\u001b[A\n",
      "Validating:  96%|█████████▋| 903/938 [00:21<00:01, 25.08it/s]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 1845/1876 [01:25<00:01, 21.50it/s, loss=0.060, v_num=29]\n",
      "Validating:  97%|█████████▋| 909/938 [00:21<00:01, 25.47it/s]\u001b[A\n",
      "Validating:  97%|█████████▋| 912/938 [00:21<00:01, 23.15it/s]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 1854/1876 [01:26<00:01, 21.50it/s, loss=0.060, v_num=29]\n",
      "Validating:  98%|█████████▊| 918/938 [00:22<00:00, 22.50it/s]\u001b[A\n",
      "Validating:  98%|█████████▊| 921/938 [00:22<00:00, 23.97it/s]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 1863/1876 [01:26<00:00, 21.52it/s, loss=0.060, v_num=29]\n",
      "Validating:  99%|█████████▉| 928/938 [00:22<00:00, 25.88it/s]\u001b[A\n",
      "Validating:  99%|█████████▉| 931/938 [00:22<00:00, 24.49it/s]\u001b[A\n",
      "Epoch 3: 100%|█████████▉| 1872/1876 [01:26<00:00, 21.52it/s, loss=0.060, v_num=29]\n",
      "Epoch 3: 100%|██████████| 1876/1876 [01:27<00:00, 21.46it/s, loss=0.060, v_num=29]\n",
      "Epoch 4:  50%|█████     | 938/1876 [01:01<01:01, 15.35it/s, loss=0.047, v_num=29]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 4:  50%|█████     | 945/1876 [01:01<01:00, 15.40it/s, loss=0.047, v_num=29]\n",
      "Validating:   1%|          | 8/938 [00:00<00:29, 31.23it/s]\u001b[A\n",
      "Validating:   1%|          | 11/938 [00:00<00:32, 28.72it/s]\u001b[A\n",
      "Epoch 4:  51%|█████     | 954/1876 [01:01<00:59, 15.46it/s, loss=0.047, v_num=29]\n",
      "Validating:   2%|▏         | 17/938 [00:00<00:32, 27.95it/s]\u001b[A\n",
      "Validating:   2%|▏         | 21/938 [00:00<00:31, 29.57it/s]\u001b[A\n",
      "Epoch 4:  51%|█████▏    | 963/1876 [01:01<00:58, 15.53it/s, loss=0.047, v_num=29]\n",
      "Validating:   3%|▎         | 29/938 [00:00<00:29, 31.29it/s]\u001b[A\n",
      "Epoch 4:  52%|█████▏    | 972/1876 [01:02<00:57, 15.61it/s, loss=0.047, v_num=29]\n",
      "Validating:   4%|▍         | 37/938 [00:01<00:29, 30.57it/s]\u001b[A\n",
      "Validating:   4%|▍         | 40/938 [00:01<00:32, 27.47it/s]\u001b[A\n",
      "Epoch 4:  52%|█████▏    | 981/1876 [01:02<00:57, 15.66it/s, loss=0.047, v_num=29]\n",
      "Validating:   5%|▍         | 46/938 [00:01<00:36, 24.17it/s]\u001b[A\n",
      "Validating:   5%|▌         | 49/938 [00:01<00:35, 25.28it/s]\u001b[A\n",
      "Epoch 4:  53%|█████▎    | 990/1876 [01:03<00:56, 15.71it/s, loss=0.047, v_num=29]\n",
      "Validating:   6%|▌         | 55/938 [00:01<00:33, 26.40it/s]\u001b[A\n",
      "Validating:   6%|▌         | 58/938 [00:02<00:36, 24.15it/s]\u001b[A\n",
      "Epoch 4:  53%|█████▎    | 999/1876 [01:03<00:55, 15.75it/s, loss=0.047, v_num=29]\n",
      "Validating:   7%|▋         | 64/938 [00:02<00:38, 22.42it/s]\u001b[A\n",
      "Validating:   7%|▋         | 67/938 [00:02<00:37, 23.14it/s]\u001b[A\n",
      "Epoch 4:  54%|█████▎    | 1008/1876 [01:03<00:54, 15.80it/s, loss=0.047, v_num=29]\n",
      "Validating:   8%|▊         | 73/938 [00:02<00:35, 24.30it/s]\u001b[A\n",
      "Validating:   8%|▊         | 76/938 [00:02<00:34, 24.81it/s]\u001b[A\n",
      "Epoch 4:  54%|█████▍    | 1017/1876 [01:04<00:54, 15.85it/s, loss=0.047, v_num=29]\n",
      "Validating:   9%|▊         | 82/938 [00:03<00:38, 22.14it/s]\u001b[A\n",
      "Validating:   9%|▉         | 85/938 [00:03<00:37, 22.88it/s]\u001b[A\n",
      "Epoch 4:  55%|█████▍    | 1026/1876 [01:04<00:53, 15.89it/s, loss=0.047, v_num=29]\n",
      "Validating:  10%|▉         | 91/938 [00:03<00:34, 24.87it/s]\u001b[A\n",
      "Epoch 4:  55%|█████▌    | 1035/1876 [01:04<00:52, 15.96it/s, loss=0.047, v_num=29]\n",
      "Validating:  11%|█         | 99/938 [00:03<00:30, 27.41it/s]\u001b[A\n",
      "Validating:  11%|█         | 102/938 [00:03<00:33, 25.04it/s]\u001b[A\n",
      "Epoch 4:  56%|█████▌    | 1044/1876 [01:05<00:51, 16.01it/s, loss=0.047, v_num=29]\n",
      "Validating:  12%|█▏        | 108/938 [00:04<00:32, 25.74it/s]\u001b[A\n",
      "Validating:  12%|█▏        | 111/938 [00:04<00:30, 26.74it/s]\u001b[A\n",
      "Epoch 4:  56%|█████▌    | 1053/1876 [01:05<00:51, 16.07it/s, loss=0.047, v_num=29]\n",
      "Validating:  13%|█▎        | 119/938 [00:04<00:27, 29.76it/s]\u001b[A\n",
      "Epoch 4:  57%|█████▋    | 1062/1876 [01:05<00:50, 16.14it/s, loss=0.047, v_num=29]\n",
      "Validating:  14%|█▎        | 127/938 [00:04<00:28, 28.90it/s]\u001b[A\n",
      "Validating:  14%|█▍        | 130/938 [00:04<00:30, 26.86it/s]\u001b[A\n",
      "Epoch 4:  57%|█████▋    | 1071/1876 [01:06<00:49, 16.19it/s, loss=0.047, v_num=29]\n",
      "Validating:  14%|█▍        | 136/938 [00:05<00:28, 27.85it/s]\u001b[A\n",
      "Epoch 4:  58%|█████▊    | 1080/1876 [01:06<00:48, 16.26it/s, loss=0.047, v_num=29]\n",
      "Validating:  15%|█▌        | 144/938 [00:05<00:26, 29.58it/s]\u001b[A\n",
      "Epoch 4:  58%|█████▊    | 1089/1876 [01:06<00:48, 16.33it/s, loss=0.047, v_num=29]\n",
      "Validating:  16%|█▌        | 152/938 [00:05<00:24, 31.70it/s]\u001b[A\n",
      "Validating:  17%|█▋        | 156/938 [00:05<00:26, 29.76it/s]\u001b[A\n",
      "Epoch 4:  59%|█████▊    | 1098/1876 [01:07<00:47, 16.37it/s, loss=0.047, v_num=29]\n",
      "Validating:  17%|█▋        | 163/938 [00:06<00:27, 28.27it/s]\u001b[A\n",
      "Epoch 4:  59%|█████▉    | 1107/1876 [01:07<00:46, 16.43it/s, loss=0.047, v_num=29]\n",
      "Validating:  18%|█▊        | 170/938 [00:06<00:26, 29.15it/s]\u001b[A\n",
      "Validating:  19%|█▊        | 174/938 [00:06<00:24, 30.78it/s]\u001b[A\n",
      "Epoch 4:  59%|█████▉    | 1116/1876 [01:07<00:46, 16.50it/s, loss=0.047, v_num=29]\n",
      "Validating:  19%|█▉        | 182/938 [00:06<00:25, 29.50it/s]\u001b[A\n",
      "Epoch 4:  60%|█████▉    | 1125/1876 [01:07<00:45, 16.55it/s, loss=0.047, v_num=29]\n",
      "Validating:  20%|██        | 189/938 [00:06<00:27, 26.83it/s]\u001b[A\n",
      "Validating:  20%|██        | 192/938 [00:07<00:27, 27.56it/s]\u001b[A\n",
      "Epoch 4:  60%|██████    | 1134/1876 [01:08<00:44, 16.60it/s, loss=0.047, v_num=29]\n",
      "Validating:  21%|██        | 198/938 [00:07<00:27, 27.36it/s]\u001b[A\n",
      "Epoch 4:  61%|██████    | 1143/1876 [01:08<00:43, 16.67it/s, loss=0.047, v_num=29]\n",
      "Epoch 4:  61%|██████▏   | 1152/1876 [01:08<00:43, 16.77it/s, loss=0.047, v_num=29]\n",
      "Validating:  23%|██▎       | 215/938 [00:07<00:18, 39.61it/s]\u001b[A\n",
      "Epoch 4:  62%|██████▏   | 1161/1876 [01:08<00:42, 16.87it/s, loss=0.047, v_num=29]\n",
      "Epoch 4:  62%|██████▏   | 1170/1876 [01:08<00:41, 16.97it/s, loss=0.047, v_num=29]\n",
      "Epoch 4:  63%|██████▎   | 1179/1876 [01:09<00:40, 17.06it/s, loss=0.047, v_num=29]\n",
      "Epoch 4:  63%|██████▎   | 1188/1876 [01:09<00:40, 17.16it/s, loss=0.047, v_num=29]\n",
      "Validating:  27%|██▋       | 252/938 [00:08<00:11, 58.08it/s]\u001b[A\n",
      "Epoch 4:  64%|██████▍   | 1197/1876 [01:09<00:39, 17.25it/s, loss=0.047, v_num=29]\n",
      "Epoch 4:  64%|██████▍   | 1206/1876 [01:09<00:38, 17.34it/s, loss=0.047, v_num=29]\n",
      "Epoch 4:  65%|██████▍   | 1215/1876 [01:09<00:37, 17.43it/s, loss=0.047, v_num=29]\n",
      "Validating:  30%|██▉       | 278/938 [00:08<00:11, 58.89it/s]\u001b[A\n",
      "Epoch 4:  65%|██████▌   | 1224/1876 [01:09<00:37, 17.52it/s, loss=0.047, v_num=29]\n",
      "Epoch 4:  66%|██████▌   | 1233/1876 [01:10<00:36, 17.61it/s, loss=0.047, v_num=29]\n",
      "Validating:  32%|███▏      | 296/938 [00:08<00:10, 58.61it/s]\u001b[A\n",
      "Epoch 4:  66%|██████▌   | 1242/1876 [01:10<00:35, 17.70it/s, loss=0.047, v_num=29]\n",
      "Epoch 4:  67%|██████▋   | 1251/1876 [01:10<00:35, 17.78it/s, loss=0.047, v_num=29]\n",
      "Validating:  33%|███▎      | 314/938 [00:09<00:11, 55.92it/s]\u001b[A\n",
      "Epoch 4:  67%|██████▋   | 1260/1876 [01:10<00:34, 17.87it/s, loss=0.047, v_num=29]\n",
      "Epoch 4:  68%|██████▊   | 1269/1876 [01:10<00:33, 17.96it/s, loss=0.047, v_num=29]\n",
      "Validating:  35%|███▌      | 332/938 [00:09<00:10, 56.23it/s]\u001b[A\n",
      "Epoch 4:  68%|██████▊   | 1278/1876 [01:10<00:33, 18.04it/s, loss=0.047, v_num=29]\n",
      "Epoch 4:  69%|██████▊   | 1287/1876 [01:10<00:32, 18.13it/s, loss=0.047, v_num=29]\n",
      "Validating:  37%|███▋      | 350/938 [00:09<00:10, 56.68it/s]\u001b[A\n",
      "Epoch 4:  69%|██████▉   | 1296/1876 [01:11<00:31, 18.22it/s, loss=0.047, v_num=29]\n",
      "Epoch 4:  70%|██████▉   | 1305/1876 [01:11<00:31, 18.30it/s, loss=0.047, v_num=29]\n",
      "Validating:  39%|███▉      | 368/938 [00:10<00:10, 55.71it/s]\u001b[A\n",
      "Epoch 4:  70%|███████   | 1314/1876 [01:11<00:30, 18.39it/s, loss=0.047, v_num=29]\n",
      "Epoch 4:  71%|███████   | 1323/1876 [01:11<00:29, 18.47it/s, loss=0.047, v_num=29]\n",
      "Validating:  41%|████▏     | 387/938 [00:10<00:09, 57.52it/s]\u001b[A\n",
      "Epoch 4:  71%|███████   | 1332/1876 [01:11<00:29, 18.56it/s, loss=0.047, v_num=29]\n",
      "Epoch 4:  71%|███████▏  | 1341/1876 [01:11<00:28, 18.64it/s, loss=0.047, v_num=29]\n",
      "Validating:  43%|████▎     | 405/938 [00:10<00:09, 54.73it/s]\u001b[A\n",
      "Epoch 4:  72%|███████▏  | 1350/1876 [01:12<00:28, 18.72it/s, loss=0.047, v_num=29]\n",
      "Epoch 4:  72%|███████▏  | 1359/1876 [01:12<00:27, 18.81it/s, loss=0.047, v_num=29]\n",
      "Validating:  45%|████▌     | 423/938 [00:11<00:09, 56.12it/s]\u001b[A\n",
      "Epoch 4:  73%|███████▎  | 1368/1876 [01:12<00:26, 18.89it/s, loss=0.047, v_num=29]\n",
      "Epoch 4:  73%|███████▎  | 1377/1876 [01:12<00:26, 18.96it/s, loss=0.047, v_num=29]\n",
      "Validating:  47%|████▋     | 441/938 [00:11<00:09, 53.50it/s]\u001b[A\n",
      "Epoch 4:  74%|███████▍  | 1386/1876 [01:12<00:25, 19.05it/s, loss=0.047, v_num=29]\n",
      "Epoch 4:  74%|███████▍  | 1395/1876 [01:12<00:25, 19.13it/s, loss=0.047, v_num=29]\n",
      "Validating:  49%|████▉     | 459/938 [00:11<00:08, 55.82it/s]\u001b[A\n",
      "Epoch 4:  75%|███████▍  | 1404/1876 [01:13<00:24, 19.21it/s, loss=0.047, v_num=29]\n",
      "Epoch 4:  75%|███████▌  | 1413/1876 [01:13<00:23, 19.29it/s, loss=0.047, v_num=29]\n",
      "Validating:  51%|█████     | 477/938 [00:12<00:08, 54.49it/s]\u001b[A\n",
      "Epoch 4:  76%|███████▌  | 1422/1876 [01:13<00:23, 19.37it/s, loss=0.047, v_num=29]\n",
      "Epoch 4:  76%|███████▋  | 1431/1876 [01:13<00:22, 19.44it/s, loss=0.047, v_num=29]\n",
      "Validating:  53%|█████▎    | 495/938 [00:12<00:08, 50.39it/s]\u001b[A\n",
      "Epoch 4:  77%|███████▋  | 1440/1876 [01:13<00:22, 19.52it/s, loss=0.047, v_num=29]\n",
      "Epoch 4:  77%|███████▋  | 1449/1876 [01:13<00:21, 19.61it/s, loss=0.047, v_num=29]\n",
      "Epoch 4:  78%|███████▊  | 1458/1876 [01:14<00:21, 19.69it/s, loss=0.047, v_num=29]\n",
      "Epoch 4:  78%|███████▊  | 1467/1876 [01:14<00:20, 19.77it/s, loss=0.047, v_num=29]\n",
      "Validating:  57%|█████▋    | 530/938 [00:13<00:06, 61.47it/s]\u001b[A\n",
      "Epoch 4:  79%|███████▊  | 1476/1876 [01:14<00:20, 19.86it/s, loss=0.047, v_num=29]\n",
      "Epoch 4:  79%|███████▉  | 1485/1876 [01:14<00:19, 19.93it/s, loss=0.047, v_num=29]\n",
      "Validating:  59%|█████▊    | 550/938 [00:13<00:06, 56.87it/s]\u001b[A\n",
      "Epoch 4:  80%|███████▉  | 1494/1876 [01:14<00:19, 20.00it/s, loss=0.047, v_num=29]\n",
      "Epoch 4:  80%|████████  | 1503/1876 [01:14<00:18, 20.07it/s, loss=0.047, v_num=29]\n",
      "Validating:  61%|██████    | 568/938 [00:13<00:07, 49.15it/s]\u001b[A\n",
      "Epoch 4:  81%|████████  | 1512/1876 [01:15<00:18, 20.13it/s, loss=0.047, v_num=29]\n",
      "Validating:  62%|██████▏   | 578/938 [00:14<00:07, 46.08it/s]\u001b[A\n",
      "Epoch 4:  81%|████████  | 1521/1876 [01:15<00:17, 20.20it/s, loss=0.047, v_num=29]\n",
      "Epoch 4:  82%|████████▏ | 1530/1876 [01:15<00:17, 20.25it/s, loss=0.047, v_num=29]\n",
      "Validating:  63%|██████▎   | 593/938 [00:14<00:08, 39.81it/s]\u001b[A\n",
      "Epoch 4:  82%|████████▏ | 1539/1876 [01:15<00:16, 20.31it/s, loss=0.047, v_num=29]\n",
      "Validating:  64%|██████▍   | 603/938 [00:14<00:08, 39.92it/s]\u001b[A\n",
      "Epoch 4:  83%|████████▎ | 1548/1876 [01:16<00:16, 20.36it/s, loss=0.047, v_num=29]\n",
      "Validating:  65%|██████▌   | 612/938 [00:14<00:09, 35.78it/s]\u001b[A\n",
      "Epoch 4:  83%|████████▎ | 1557/1876 [01:16<00:15, 20.39it/s, loss=0.047, v_num=29]\n",
      "Validating:  66%|██████▌   | 620/938 [00:15<00:09, 32.40it/s]\u001b[A\n",
      "Validating:  67%|██████▋   | 624/938 [00:15<00:09, 32.60it/s]\u001b[A\n",
      "Epoch 4:  83%|████████▎ | 1566/1876 [01:16<00:15, 20.44it/s, loss=0.047, v_num=29]\n",
      "Validating:  67%|██████▋   | 632/938 [00:15<00:08, 35.35it/s]\u001b[A\n",
      "Epoch 4:  84%|████████▍ | 1575/1876 [01:16<00:14, 20.50it/s, loss=0.047, v_num=29]\n",
      "Validating:  68%|██████▊   | 640/938 [00:15<00:08, 36.02it/s]\u001b[A\n",
      "Epoch 4:  84%|████████▍ | 1584/1876 [01:17<00:14, 20.55it/s, loss=0.047, v_num=29]\n",
      "Validating:  69%|██████▉   | 648/938 [00:16<00:08, 35.13it/s]\u001b[A\n",
      "Epoch 4:  85%|████████▍ | 1593/1876 [01:17<00:13, 20.58it/s, loss=0.047, v_num=29]\n",
      "Validating:  70%|██████▉   | 656/938 [00:16<00:09, 30.44it/s]\u001b[A\n",
      "Validating:  70%|███████   | 660/938 [00:16<00:08, 31.70it/s]\u001b[A\n",
      "Epoch 4:  85%|████████▌ | 1602/1876 [01:17<00:13, 20.63it/s, loss=0.047, v_num=29]\n",
      "Validating:  71%|███████   | 668/938 [00:16<00:07, 34.05it/s]\u001b[A\n",
      "Epoch 4:  86%|████████▌ | 1611/1876 [01:17<00:12, 20.68it/s, loss=0.047, v_num=29]\n",
      "Validating:  72%|███████▏  | 676/938 [00:16<00:07, 35.82it/s]\u001b[A\n",
      "Epoch 4:  86%|████████▋ | 1620/1876 [01:18<00:12, 20.72it/s, loss=0.047, v_num=29]\n",
      "Validating:  73%|███████▎  | 684/938 [00:17<00:07, 34.03it/s]\u001b[A\n",
      "Epoch 4:  87%|████████▋ | 1629/1876 [01:18<00:11, 20.75it/s, loss=0.047, v_num=29]\n",
      "Validating:  74%|███████▍  | 692/938 [00:17<00:08, 28.90it/s]\u001b[A\n",
      "Validating:  74%|███████▍  | 695/938 [00:17<00:08, 27.16it/s]\u001b[A\n",
      "Epoch 4:  87%|████████▋ | 1638/1876 [01:18<00:11, 20.77it/s, loss=0.047, v_num=29]\n",
      "Validating:  75%|███████▍  | 702/938 [00:17<00:08, 28.41it/s]\u001b[A\n",
      "Epoch 4:  88%|████████▊ | 1647/1876 [01:19<00:10, 20.82it/s, loss=0.047, v_num=29]\n",
      "Validating:  76%|███████▌  | 710/938 [00:17<00:07, 32.11it/s]\u001b[A\n",
      "Validating:  76%|███████▌  | 714/938 [00:18<00:06, 33.11it/s]\u001b[A\n",
      "Epoch 4:  88%|████████▊ | 1656/1876 [01:19<00:10, 20.86it/s, loss=0.047, v_num=29]\n",
      "Validating:  77%|███████▋  | 722/938 [00:18<00:07, 29.07it/s]\u001b[A\n",
      "Epoch 4:  89%|████████▉ | 1665/1876 [01:19<00:10, 20.89it/s, loss=0.047, v_num=29]\n",
      "Validating:  78%|███████▊  | 730/938 [00:18<00:06, 30.93it/s]\u001b[A\n",
      "Epoch 4:  89%|████████▉ | 1674/1876 [01:19<00:09, 20.93it/s, loss=0.047, v_num=29]\n",
      "Validating:  79%|███████▊  | 738/938 [00:18<00:06, 33.11it/s]\u001b[A\n",
      "Epoch 4:  90%|████████▉ | 1683/1876 [01:20<00:09, 20.98it/s, loss=0.047, v_num=29]\n",
      "Validating:  80%|███████▉  | 746/938 [00:19<00:05, 32.23it/s]\u001b[A\n",
      "Validating:  80%|███████▉  | 750/938 [00:19<00:06, 29.59it/s]\u001b[A\n",
      "Epoch 4:  90%|█████████ | 1692/1876 [01:20<00:08, 21.00it/s, loss=0.047, v_num=29]\n",
      "Epoch 4:  91%|█████████ | 1701/1876 [01:20<00:08, 21.07it/s, loss=0.047, v_num=29]\n",
      "Epoch 4:  91%|█████████ | 1710/1876 [01:20<00:07, 21.15it/s, loss=0.047, v_num=29]\n",
      "Epoch 4:  92%|█████████▏| 1719/1876 [01:20<00:07, 21.23it/s, loss=0.047, v_num=29]\n",
      "Validating:  83%|████████▎ | 782/938 [00:19<00:03, 51.82it/s]\u001b[A\n",
      "Epoch 4:  92%|█████████▏| 1728/1876 [01:21<00:06, 21.30it/s, loss=0.047, v_num=29]\n",
      "Epoch 4:  93%|█████████▎| 1737/1876 [01:21<00:06, 21.38it/s, loss=0.047, v_num=29]\n",
      "Epoch 4:  93%|█████████▎| 1746/1876 [01:21<00:06, 21.45it/s, loss=0.047, v_num=29]\n",
      "Validating:  86%|████████▋ | 810/938 [00:20<00:02, 58.67it/s]\u001b[A\n",
      "Epoch 4:  94%|█████████▎| 1755/1876 [01:21<00:05, 21.52it/s, loss=0.047, v_num=29]\n",
      "Epoch 4:  94%|█████████▍| 1764/1876 [01:21<00:05, 21.59it/s, loss=0.047, v_num=29]\n",
      "Epoch 4:  95%|█████████▍| 1773/1876 [01:21<00:04, 21.66it/s, loss=0.047, v_num=29]\n",
      "Validating:  89%|████████▉ | 837/938 [00:20<00:01, 58.45it/s]\u001b[A\n",
      "Epoch 4:  95%|█████████▍| 1782/1876 [01:22<00:04, 21.73it/s, loss=0.047, v_num=29]\n",
      "Epoch 4:  95%|█████████▌| 1791/1876 [01:22<00:03, 21.79it/s, loss=0.047, v_num=29]\n",
      "Validating:  91%|█████████ | 855/938 [00:21<00:01, 56.76it/s]\u001b[A\n",
      "Epoch 4:  96%|█████████▌| 1800/1876 [01:22<00:03, 21.86it/s, loss=0.047, v_num=29]\n",
      "Epoch 4:  96%|█████████▋| 1809/1876 [01:22<00:03, 21.93it/s, loss=0.047, v_num=29]\n",
      "Validating:  93%|█████████▎| 873/938 [00:21<00:01, 55.40it/s]\u001b[A\n",
      "Epoch 4:  97%|█████████▋| 1818/1876 [01:22<00:02, 21.99it/s, loss=0.047, v_num=29]\n",
      "Epoch 4:  97%|█████████▋| 1827/1876 [01:22<00:02, 22.06it/s, loss=0.047, v_num=29]\n",
      "Validating:  95%|█████████▍| 891/938 [00:21<00:00, 55.90it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 1836/1876 [01:22<00:01, 22.12it/s, loss=0.047, v_num=29]\n",
      "Epoch 4:  98%|█████████▊| 1845/1876 [01:23<00:01, 22.19it/s, loss=0.047, v_num=29]\n",
      "Validating:  97%|█████████▋| 909/938 [00:22<00:00, 53.80it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▉| 1854/1876 [01:23<00:00, 22.24it/s, loss=0.047, v_num=29]\n",
      "Epoch 4:  99%|█████████▉| 1863/1876 [01:23<00:00, 22.31it/s, loss=0.047, v_num=29]\n",
      "Epoch 4: 100%|█████████▉| 1872/1876 [01:23<00:00, 22.38it/s, loss=0.047, v_num=29]\n",
      "Epoch 4: 100%|██████████| 1876/1876 [01:23<00:00, 22.37it/s, loss=0.047, v_num=29]\n",
      "Epoch 4: 100%|██████████| 1876/1876 [01:23<00:00, 22.37it/s, loss=0.047, v_num=29]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "model = BRNN(input_size, hidden_size, num_layers, num_classes)   \n",
    "# most basic trainer, uses good defaults (1 gpu)\n",
    "trainer = pl.Trainer(gpus = 1,max_epochs=5)    \n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Testing:  99%|█████████▊| 155/157 [00:03<00:00, 37.99it/s]--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_loss': tensor(0.0489, device='cuda:0')}\n",
      "--------------------------------------------------------------------------------\n",
      "Testing: 100%|██████████| 157/157 [00:03<00:00, 44.39it/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'test_loss': 0.0489131435751915}]"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}