{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "import pytorch_lightning as pl\n",
    "from torch import nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 28\n",
    "hidden_size = 256\n",
    "num_layers = 2\n",
    "num_classes = 10\n",
    "sequence_length = 28\n",
    "learning_rate = 0.005\n",
    "batch_size = 64\n",
    "num_epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_LSTM(pl.LightningModule):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNN_LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size * sequence_length, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(self.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(self.device)\n",
    "\n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        out = out.reshape(out.shape[0], -1)\n",
    "\n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "    def training_step(self, batch, batch_nb):\n",
    "        # REQUIRED\n",
    "        x, y = batch\n",
    "        x = x.squeeze(1)\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        tensorboard_logs = {'train_loss': loss}\n",
    "        return {'loss': loss, 'log': tensorboard_logs}\n",
    "\n",
    "    def validation_step(self, batch, batch_nb):\n",
    "        # OPTIONAL\n",
    "        x, y = batch\n",
    "        x = x.squeeze(1)\n",
    "        y_hat = self(x)\n",
    "        return {'val_loss': F.cross_entropy(y_hat, y)}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        # OPTIONAL\n",
    "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        tensorboard_logs = {'val_loss': avg_loss}\n",
    "        return {'val_loss': avg_loss, 'log': tensorboard_logs}\n",
    "\n",
    "    def test_step(self, batch, batch_nb):\n",
    "        # OPTIONAL\n",
    "        x, y = batch\n",
    "        x = x.squeeze(1)\n",
    "        y_hat = self(x)\n",
    "        return {'test_loss': F.cross_entropy(y_hat, y)}\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "        # OPTIONAL\n",
    "        avg_loss = torch.stack([x['test_loss'] for x in outputs]).mean()\n",
    "        logs = {'test_loss': avg_loss}\n",
    "        return {'test_loss': avg_loss, 'log': logs, 'progress_bar': logs}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # REQUIRED\n",
    "        # can return multiple optimizers and learning_rate schedulers\n",
    "        # (LBFGS it is automatically supported, no need for closure function)\n",
    "        return torch.optim.Adam(self.parameters(), lr=learning_rate)\n",
    "\n",
    "    def prepare_data(self):\n",
    "        self.train_dataset = MNIST(root=\"dataset/\", train=True, transform=transforms.ToTensor(), download=True)\n",
    "        self.test_dataset = MNIST(root=\"dataset/\", train=True, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        # REQUIRED\n",
    "        return DataLoader(dataset=self.train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        # OPTIONAL\n",
    "        return DataLoader(dataset=self.train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        # OPTIONAL\n",
    "        return DataLoader(dataset=self.test_dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      ":33, 26.92it/s, loss=0.046, v_num=5]\n",
      "Validating:   4%|▍         | 40/938 [00:00<00:17, 51.78it/s]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 988/1876 [00:36<00:32, 27.11it/s, loss=0.046, v_num=5]\n",
      "Validating:   6%|▌         | 52/938 [00:00<00:16, 53.31it/s]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 1001/1876 [00:36<00:32, 27.27it/s, loss=0.046, v_num=5]\n",
      "Validating:   7%|▋         | 64/938 [00:01<00:17, 50.43it/s]\u001b[A\n",
      "Validating:   7%|▋         | 70/938 [00:01<00:16, 51.86it/s]\u001b[A\n",
      "Epoch 3:  54%|█████▍    | 1014/1876 [00:36<00:31, 27.44it/s, loss=0.046, v_num=5]\n",
      "Validating:   9%|▊         | 82/938 [00:01<00:16, 52.65it/s]\u001b[A\n",
      "Epoch 3:  55%|█████▍    | 1027/1876 [00:37<00:30, 27.59it/s, loss=0.046, v_num=5]\n",
      "Validating:  10%|█         | 94/938 [00:01<00:17, 48.45it/s]\u001b[A\n",
      "Epoch 3:  55%|█████▌    | 1040/1876 [00:37<00:30, 27.75it/s, loss=0.046, v_num=5]\n",
      "Validating:  11%|█▏        | 106/938 [00:02<00:16, 50.41it/s]\u001b[A\n",
      "Epoch 3:  56%|█████▌    | 1053/1876 [00:37<00:29, 27.89it/s, loss=0.046, v_num=5]\n",
      "Validating:  13%|█▎        | 118/938 [00:02<00:16, 49.00it/s]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 1066/1876 [00:37<00:28, 28.06it/s, loss=0.046, v_num=5]\n",
      "Validating:  14%|█▍        | 130/938 [00:02<00:15, 52.07it/s]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 1079/1876 [00:38<00:28, 28.24it/s, loss=0.046, v_num=5]\n",
      "Validating:  15%|█▌        | 143/938 [00:02<00:14, 54.52it/s]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 1092/1876 [00:38<00:27, 28.41it/s, loss=0.046, v_num=5]\n",
      "Validating:  17%|█▋        | 155/938 [00:02<00:14, 55.81it/s]\u001b[A\n",
      "Epoch 3:  59%|█████▉    | 1105/1876 [00:38<00:26, 28.58it/s, loss=0.046, v_num=5]\n",
      "Validating:  18%|█▊        | 168/938 [00:03<00:13, 57.18it/s]\u001b[A\n",
      "Validating:  19%|█▊        | 174/938 [00:03<00:13, 57.17it/s]\u001b[A\n",
      "Epoch 3:  60%|█████▉    | 1118/1876 [00:38<00:26, 28.75it/s, loss=0.046, v_num=5]\n",
      "Validating:  20%|█▉        | 186/938 [00:03<00:12, 57.93it/s]\u001b[A\n",
      "Epoch 3:  60%|██████    | 1131/1876 [00:39<00:25, 28.92it/s, loss=0.046, v_num=5]\n",
      "Validating:  21%|██        | 199/938 [00:03<00:12, 59.07it/s]\u001b[A\n",
      "Epoch 3:  61%|██████    | 1144/1876 [00:39<00:25, 29.09it/s, loss=0.046, v_num=5]\n",
      "Validating:  23%|██▎       | 212/938 [00:03<00:12, 58.29it/s]\u001b[A\n",
      "Epoch 3:  62%|██████▏   | 1157/1876 [00:39<00:24, 29.25it/s, loss=0.046, v_num=5]\n",
      "Validating:  24%|██▍       | 224/938 [00:04<00:12, 57.58it/s]\u001b[A\n",
      "Epoch 3:  62%|██████▏   | 1170/1876 [00:39<00:24, 29.41it/s, loss=0.046, v_num=5]\n",
      "Validating:  25%|██▌       | 236/938 [00:04<00:12, 55.36it/s]\u001b[A\n",
      "Epoch 3:  63%|██████▎   | 1183/1876 [00:40<00:23, 29.57it/s, loss=0.046, v_num=5]\n",
      "Validating:  27%|██▋       | 250/938 [00:04<00:11, 58.23it/s]\u001b[A\n",
      "Epoch 3:  64%|██████▍   | 1196/1876 [00:40<00:22, 29.73it/s, loss=0.046, v_num=5]\n",
      "Validating:  28%|██▊       | 263/938 [00:04<00:12, 54.04it/s]\u001b[A\n",
      "Epoch 3:  64%|██████▍   | 1209/1876 [00:40<00:22, 29.84it/s, loss=0.046, v_num=5]\n",
      "Validating:  29%|██▉       | 275/938 [00:05<00:12, 51.38it/s]\u001b[A\n",
      "Epoch 3:  65%|██████▌   | 1222/1876 [00:40<00:21, 29.98it/s, loss=0.046, v_num=5]\n",
      "Validating:  31%|███       | 287/938 [00:05<00:12, 53.43it/s]\u001b[A\n",
      "Epoch 3:  66%|██████▌   | 1235/1876 [00:40<00:21, 30.12it/s, loss=0.046, v_num=5]\n",
      "Validating:  32%|███▏      | 300/938 [00:05<00:11, 54.04it/s]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 1248/1876 [00:41<00:20, 30.28it/s, loss=0.046, v_num=5]\n",
      "Validating:  33%|███▎      | 314/938 [00:05<00:10, 57.57it/s]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 1261/1876 [00:41<00:20, 30.43it/s, loss=0.046, v_num=5]\n",
      "Validating:  35%|███▍      | 327/938 [00:06<00:10, 58.24it/s]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 1274/1876 [00:41<00:19, 30.57it/s, loss=0.046, v_num=5]\n",
      "Validating:  36%|███▌      | 339/938 [00:06<00:10, 55.28it/s]\u001b[A\n",
      "Epoch 3:  69%|██████▊   | 1287/1876 [00:41<00:19, 30.70it/s, loss=0.046, v_num=5]\n",
      "Validating:  37%|███▋      | 351/938 [00:06<00:11, 53.32it/s]\u001b[A\n",
      "Epoch 3:  69%|██████▉   | 1300/1876 [00:42<00:18, 30.84it/s, loss=0.046, v_num=5]\n",
      "Validating:  39%|███▊      | 363/938 [00:06<00:10, 53.84it/s]\u001b[A\n",
      "Validating:  39%|███▉      | 369/938 [00:06<00:10, 54.49it/s]\u001b[A\n",
      "Epoch 3:  70%|██████▉   | 1313/1876 [00:42<00:18, 30.96it/s, loss=0.046, v_num=5]\n",
      "Validating:  41%|████      | 381/938 [00:07<00:10, 52.67it/s]\u001b[A\n",
      "Epoch 3:  71%|███████   | 1326/1876 [00:42<00:17, 31.09it/s, loss=0.046, v_num=5]\n",
      "Validating:  42%|████▏     | 393/938 [00:07<00:10, 53.88it/s]\u001b[A\n",
      "Epoch 3:  71%|███████▏  | 1339/1876 [00:42<00:17, 31.21it/s, loss=0.046, v_num=5]\n",
      "Validating:  43%|████▎     | 405/938 [00:07<00:10, 50.69it/s]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 1352/1876 [00:43<00:16, 31.33it/s, loss=0.046, v_num=5]\n",
      "Validating:  44%|████▍     | 417/938 [00:07<00:09, 53.38it/s]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 1365/1876 [00:43<00:16, 31.47it/s, loss=0.046, v_num=5]\n",
      "Validating:  46%|████▌     | 429/938 [00:07<00:09, 55.93it/s]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 1378/1876 [00:43<00:15, 31.60it/s, loss=0.046, v_num=5]\n",
      "Validating:  47%|████▋     | 441/938 [00:08<00:08, 55.79it/s]\u001b[A\n",
      "Validating:  48%|████▊     | 447/938 [00:08<00:08, 56.98it/s]\u001b[A\n",
      "Epoch 3:  74%|███████▍  | 1391/1876 [00:43<00:15, 31.73it/s, loss=0.046, v_num=5]\n",
      "Validating:  49%|████▉     | 459/938 [00:08<00:08, 55.24it/s]\u001b[A\n",
      "Epoch 3:  75%|███████▍  | 1404/1876 [00:44<00:14, 31.86it/s, loss=0.046, v_num=5]\n",
      "Validating:  50%|█████     | 471/938 [00:08<00:08, 55.49it/s]\u001b[A\n",
      "Epoch 3:  76%|███████▌  | 1417/1876 [00:44<00:14, 31.99it/s, loss=0.046, v_num=5]\n",
      "Validating:  51%|█████▏    | 483/938 [00:08<00:07, 56.98it/s]\u001b[A\n",
      "Epoch 3:  76%|███████▌  | 1430/1876 [00:44<00:13, 32.11it/s, loss=0.046, v_num=5]\n",
      "Validating:  53%|█████▎    | 495/938 [00:09<00:07, 56.98it/s]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 1443/1876 [00:44<00:13, 32.23it/s, loss=0.046, v_num=5]\n",
      "Validating:  54%|█████▍    | 507/938 [00:09<00:07, 55.68it/s]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 1456/1876 [00:44<00:12, 32.36it/s, loss=0.046, v_num=5]\n",
      "Validating:  55%|█████▌    | 519/938 [00:09<00:07, 56.20it/s]\u001b[A\n",
      "Validating:  56%|█████▌    | 525/938 [00:09<00:07, 56.80it/s]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 1469/1876 [00:45<00:12, 32.48it/s, loss=0.046, v_num=5]\n",
      "Validating:  57%|█████▋    | 537/938 [00:09<00:07, 57.09it/s]\u001b[A\n",
      "Epoch 3:  79%|███████▉  | 1482/1876 [00:45<00:12, 32.58it/s, loss=0.046, v_num=5]\n",
      "Validating:  59%|█████▊    | 549/938 [00:10<00:07, 51.68it/s]\u001b[A\n",
      "Epoch 3:  80%|███████▉  | 1495/1876 [00:45<00:11, 32.70it/s, loss=0.046, v_num=5]\n",
      "Validating:  60%|█████▉    | 561/938 [00:10<00:07, 51.80it/s]\u001b[A\n",
      "Epoch 3:  80%|████████  | 1508/1876 [00:45<00:11, 32.79it/s, loss=0.046, v_num=5]\n",
      "Validating:  61%|██████    | 573/938 [00:10<00:07, 49.53it/s]\u001b[A\n",
      "Validating:  62%|██████▏   | 578/938 [00:10<00:07, 49.09it/s]\u001b[A\n",
      "Epoch 3:  81%|████████  | 1521/1876 [00:46<00:10, 32.87it/s, loss=0.046, v_num=5]\n",
      "Validating:  63%|██████▎   | 588/938 [00:10<00:07, 45.71it/s]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 1534/1876 [00:46<00:10, 32.94it/s, loss=0.046, v_num=5]\n",
      "Validating:  64%|██████▍   | 598/938 [00:11<00:07, 44.57it/s]\u001b[A\n",
      "Validating:  64%|██████▍   | 603/938 [00:11<00:07, 43.43it/s]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 1547/1876 [00:46<00:09, 32.99it/s, loss=0.046, v_num=5]\n",
      "Validating:  65%|██████▌   | 613/938 [00:11<00:08, 40.13it/s]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 1560/1876 [00:47<00:09, 33.04it/s, loss=0.046, v_num=5]\n",
      "Validating:  66%|██████▋   | 623/938 [00:11<00:07, 41.30it/s]\u001b[A\n",
      "Validating:  67%|██████▋   | 628/938 [00:11<00:07, 42.36it/s]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 1573/1876 [00:47<00:09, 33.09it/s, loss=0.046, v_num=5]\n",
      "Validating:  68%|██████▊   | 638/938 [00:12<00:07, 39.83it/s]\u001b[A\n",
      "Validating:  69%|██████▊   | 643/938 [00:12<00:07, 38.67it/s]\u001b[A\n",
      "Epoch 3:  85%|████████▍ | 1586/1876 [00:47<00:08, 33.12it/s, loss=0.046, v_num=5]\n",
      "Validating:  70%|██████▉   | 652/938 [00:12<00:07, 39.99it/s]\u001b[A\n",
      "Epoch 3:  85%|████████▌ | 1599/1876 [00:48<00:08, 33.18it/s, loss=0.046, v_num=5]\n",
      "Validating:  71%|███████   | 662/938 [00:12<00:06, 41.64it/s]\u001b[A\n",
      "Validating:  71%|███████   | 667/938 [00:12<00:06, 40.24it/s]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 1612/1876 [00:48<00:07, 33.25it/s, loss=0.046, v_num=5]\n",
      "Validating:  72%|███████▏  | 678/938 [00:13<00:05, 44.74it/s]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 1625/1876 [00:48<00:07, 33.34it/s, loss=0.046, v_num=5]\n",
      "Validating:  73%|███████▎  | 689/938 [00:13<00:05, 46.30it/s]\u001b[A\n",
      "Validating:  74%|███████▍  | 694/938 [00:13<00:05, 46.82it/s]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 1638/1876 [00:49<00:07, 33.42it/s, loss=0.046, v_num=5]\n",
      "Validating:  75%|███████▌  | 705/938 [00:13<00:04, 47.24it/s]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 1651/1876 [00:49<00:06, 33.50it/s, loss=0.046, v_num=5]\n",
      "Validating:  76%|███████▋  | 716/938 [00:13<00:04, 49.02it/s]\u001b[A\n",
      "Epoch 3:  89%|████████▊ | 1664/1876 [00:49<00:06, 33.60it/s, loss=0.046, v_num=5]\n",
      "Validating:  78%|███████▊  | 728/938 [00:14<00:04, 51.73it/s]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 1677/1876 [00:49<00:05, 33.70it/s, loss=0.046, v_num=5]\n",
      "Validating:  79%|███████▉  | 740/938 [00:14<00:03, 53.32it/s]\u001b[A\n",
      "Validating:  80%|███████▉  | 746/938 [00:14<00:03, 54.71it/s]\u001b[A\n",
      "Epoch 3:  90%|█████████ | 1690/1876 [00:49<00:05, 33.80it/s, loss=0.046, v_num=5]\n",
      "Validating:  81%|████████  | 758/938 [00:14<00:03, 53.49it/s]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 1703/1876 [00:50<00:05, 33.87it/s, loss=0.046, v_num=5]\n",
      "Validating:  82%|████████▏ | 770/938 [00:14<00:03, 50.23it/s]\u001b[A\n",
      "Epoch 3:  91%|█████████▏| 1716/1876 [00:50<00:04, 33.98it/s, loss=0.046, v_num=5]\n",
      "Validating:  83%|████████▎ | 783/938 [00:15<00:02, 54.69it/s]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 1729/1876 [00:50<00:04, 34.08it/s, loss=0.046, v_num=5]\n",
      "Validating:  85%|████████▍ | 795/938 [00:15<00:02, 54.80it/s]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 1742/1876 [00:50<00:03, 34.19it/s, loss=0.046, v_num=5]\n",
      "Validating:  86%|████████▌ | 808/938 [00:15<00:02, 57.43it/s]\u001b[A\n",
      "Epoch 3:  94%|█████████▎| 1755/1876 [00:51<00:03, 34.29it/s, loss=0.046, v_num=5]\n",
      "Validating:  87%|████████▋ | 820/938 [00:15<00:02, 57.19it/s]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 1768/1876 [00:51<00:03, 34.37it/s, loss=0.046, v_num=5]\n",
      "Validating:  89%|████████▊ | 832/938 [00:15<00:02, 51.38it/s]\u001b[A\n",
      "Epoch 3:  95%|█████████▍| 1781/1876 [00:51<00:02, 34.45it/s, loss=0.046, v_num=5]\n",
      "Validating:  90%|████████▉ | 844/938 [00:16<00:01, 50.12it/s]\u001b[A\n",
      "Validating:  91%|█████████ | 850/938 [00:16<00:01, 50.08it/s]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 1794/1876 [00:51<00:02, 34.53it/s, loss=0.046, v_num=5]\n",
      "Validating:  92%|█████████▏| 862/938 [00:16<00:01, 50.93it/s]\u001b[A\n",
      "Epoch 3:  96%|█████████▋| 1807/1876 [00:52<00:01, 34.60it/s, loss=0.046, v_num=5]\n",
      "Validating:  93%|█████████▎| 874/938 [00:16<00:01, 51.22it/s]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 1820/1876 [00:52<00:01, 34.70it/s, loss=0.046, v_num=5]\n",
      "Validating:  94%|█████████▍| 886/938 [00:17<00:00, 53.53it/s]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 1833/1876 [00:52<00:01, 34.79it/s, loss=0.046, v_num=5]\n",
      "Validating:  96%|█████████▌| 898/938 [00:17<00:00, 55.36it/s]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 1846/1876 [00:52<00:00, 34.89it/s, loss=0.046, v_num=5]\n",
      "Validating:  97%|█████████▋| 910/938 [00:17<00:00, 55.52it/s]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 1859/1876 [00:53<00:00, 34.98it/s, loss=0.046, v_num=5]\n",
      "Validating:  98%|█████████▊| 922/938 [00:17<00:00, 55.99it/s]\u001b[A\n",
      "Epoch 3: 100%|█████████▉| 1872/1876 [00:53<00:00, 35.08it/s, loss=0.046, v_num=5]\n",
      "Epoch 3: 100%|██████████| 1876/1876 [00:53<00:00, 35.06it/s, loss=0.046, v_num=5]\n",
      "Epoch 4:  50%|█████     | 938/1876 [00:34<00:34, 26.86it/s, loss=0.034, v_num=5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   1%|          | 5/938 [00:00<00:21, 42.74it/s]\u001b[A\n",
      "Epoch 4:  51%|█████     | 949/1876 [00:35<00:34, 26.98it/s, loss=0.034, v_num=5]\n",
      "Validating:   2%|▏         | 15/938 [00:00<00:20, 45.46it/s]\u001b[A\n",
      "Epoch 4:  51%|█████▏    | 962/1876 [00:35<00:33, 27.13it/s, loss=0.034, v_num=5]\n",
      "Validating:   3%|▎         | 25/938 [00:00<00:20, 43.93it/s]\u001b[A\n",
      "Validating:   3%|▎         | 31/938 [00:00<00:19, 46.01it/s]\u001b[A\n",
      "Epoch 4:  52%|█████▏    | 975/1876 [00:35<00:33, 27.30it/s, loss=0.034, v_num=5]\n",
      "Validating:   5%|▍         | 43/938 [00:00<00:18, 48.64it/s]\u001b[A\n",
      "Epoch 4:  53%|█████▎    | 988/1876 [00:35<00:32, 27.47it/s, loss=0.034, v_num=5]\n",
      "Validating:   6%|▌         | 55/938 [00:01<00:17, 51.23it/s]\u001b[A\n",
      "Epoch 4:  53%|█████▎    | 1001/1876 [00:36<00:31, 27.66it/s, loss=0.034, v_num=5]\n",
      "Validating:   7%|▋         | 67/938 [00:01<00:15, 54.58it/s]\u001b[A\n",
      "Epoch 4:  54%|█████▍    | 1014/1876 [00:36<00:30, 27.83it/s, loss=0.034, v_num=5]\n",
      "Validating:   8%|▊         | 79/938 [00:01<00:16, 53.21it/s]\u001b[A\n",
      "Epoch 4:  55%|█████▍    | 1027/1876 [00:36<00:30, 28.00it/s, loss=0.034, v_num=5]\n",
      "Validating:  10%|▉         | 91/938 [00:01<00:15, 54.43it/s]\u001b[A\n",
      "Epoch 4:  55%|█████▌    | 1040/1876 [00:36<00:29, 28.19it/s, loss=0.034, v_num=5]\n",
      "Validating:  11%|█         | 104/938 [00:02<00:14, 56.65it/s]\u001b[A\n",
      "Epoch 4:  56%|█████▌    | 1053/1876 [00:37<00:29, 28.37it/s, loss=0.034, v_num=5]\n",
      "Validating:  12%|█▏        | 116/938 [00:02<00:14, 57.06it/s]\u001b[A\n",
      "Validating:  13%|█▎        | 122/938 [00:02<00:14, 56.28it/s]\u001b[A\n",
      "Epoch 4:  57%|█████▋    | 1066/1876 [00:37<00:28, 28.53it/s, loss=0.034, v_num=5]\n",
      "Validating:  14%|█▍        | 134/938 [00:02<00:14, 54.24it/s]\u001b[A\n",
      "Epoch 4:  58%|█████▊    | 1079/1876 [00:37<00:27, 28.71it/s, loss=0.034, v_num=5]\n",
      "Validating:  16%|█▌        | 147/938 [00:02<00:14, 53.32it/s]\u001b[A\n",
      "Epoch 4:  58%|█████▊    | 1092/1876 [00:37<00:27, 28.87it/s, loss=0.034, v_num=5]\n",
      "Validating:  17%|█▋        | 160/938 [00:03<00:14, 54.83it/s]\u001b[A\n",
      "Epoch 4:  59%|█████▉    | 1105/1876 [00:38<00:26, 29.04it/s, loss=0.034, v_num=5]\n",
      "Validating:  18%|█▊        | 173/938 [00:03<00:14, 54.33it/s]\u001b[A\n",
      "Epoch 4:  60%|█████▉    | 1118/1876 [00:38<00:25, 29.19it/s, loss=0.034, v_num=5]\n",
      "Validating:  20%|█▉        | 185/938 [00:03<00:13, 53.84it/s]\u001b[A\n",
      "Epoch 4:  60%|██████    | 1131/1876 [00:38<00:25, 29.34it/s, loss=0.034, v_num=5]\n",
      "Validating:  21%|██        | 197/938 [00:03<00:13, 53.59it/s]\u001b[A\n",
      "Epoch 4:  61%|██████    | 1144/1876 [00:38<00:24, 29.49it/s, loss=0.034, v_num=5]\n",
      "Validating:  22%|██▏       | 209/938 [00:03<00:13, 53.38it/s]\u001b[A\n",
      "Epoch 4:  62%|██████▏   | 1157/1876 [00:39<00:24, 29.64it/s, loss=0.034, v_num=5]\n",
      "Validating:  24%|██▎       | 221/938 [00:04<00:13, 54.15it/s]\u001b[A\n",
      "Epoch 4:  62%|██████▏   | 1170/1876 [00:39<00:23, 29.79it/s, loss=0.034, v_num=5]\n",
      "Validating:  25%|██▍       | 233/938 [00:04<00:13, 53.61it/s]\u001b[A\n",
      "Validating:  25%|██▌       | 239/938 [00:04<00:12, 55.22it/s]\u001b[A\n",
      "Epoch 4:  63%|██████▎   | 1183/1876 [00:39<00:23, 29.95it/s, loss=0.034, v_num=5]\n",
      "Validating:  27%|██▋       | 251/938 [00:04<00:12, 55.92it/s]\u001b[A\n",
      "Epoch 4:  64%|██████▍   | 1196/1876 [00:39<00:22, 30.10it/s, loss=0.034, v_num=5]\n",
      "Validating:  28%|██▊       | 263/938 [00:04<00:12, 55.44it/s]\u001b[A\n",
      "Epoch 4:  64%|██████▍   | 1209/1876 [00:39<00:22, 30.25it/s, loss=0.034, v_num=5]\n",
      "Validating:  29%|██▉       | 275/938 [00:05<00:11, 56.34it/s]\u001b[A\n",
      "Epoch 4:  65%|██████▌   | 1222/1876 [00:40<00:21, 30.39it/s, loss=0.034, v_num=5]\n",
      "Validating:  31%|███       | 287/938 [00:05<00:11, 54.28it/s]\u001b[A\n",
      "Epoch 4:  66%|██████▌   | 1235/1876 [00:40<00:20, 30.54it/s, loss=0.034, v_num=5]\n",
      "Validating:  32%|███▏      | 299/938 [00:05<00:11, 55.81it/s]\u001b[A\n",
      "Epoch 4:  67%|██████▋   | 1248/1876 [00:40<00:20, 30.69it/s, loss=0.034, v_num=5]\n",
      "Validating:  33%|███▎      | 311/938 [00:05<00:11, 55.88it/s]\u001b[A\n",
      "Validating:  34%|███▍      | 317/938 [00:05<00:10, 56.73it/s]\u001b[A\n",
      "Epoch 4:  67%|██████▋   | 1261/1876 [00:40<00:19, 30.84it/s, loss=0.034, v_num=5]\n",
      "Validating:  35%|███▌      | 329/938 [00:06<00:10, 57.06it/s]\u001b[A\n",
      "Epoch 4:  68%|██████▊   | 1274/1876 [00:41<00:19, 30.98it/s, loss=0.034, v_num=5]\n",
      "Validating:  36%|███▋      | 341/938 [00:06<00:10, 56.20it/s]\u001b[A\n",
      "Epoch 4:  69%|██████▊   | 1287/1876 [00:41<00:18, 31.12it/s, loss=0.034, v_num=5]\n",
      "Validating:  38%|███▊      | 354/938 [00:06<00:10, 57.25it/s]\u001b[A\n",
      "Epoch 4:  69%|██████▉   | 1300/1876 [00:41<00:18, 31.27it/s, loss=0.034, v_num=5]\n",
      "Epoch 4:  70%|██████▉   | 1313/1876 [00:41<00:17, 31.46it/s, loss=0.034, v_num=5]\n",
      "Validating:  40%|████      | 377/938 [00:06<00:08, 65.97it/s]\u001b[A\n",
      "Epoch 4:  71%|███████   | 1326/1876 [00:41<00:17, 31.65it/s, loss=0.034, v_num=5]\n",
      "Epoch 4:  71%|███████▏  | 1339/1876 [00:42<00:16, 31.88it/s, loss=0.034, v_num=5]\n",
      "Epoch 4:  72%|███████▏  | 1352/1876 [00:42<00:16, 32.09it/s, loss=0.034, v_num=5]\n",
      "Epoch 4:  73%|███████▎  | 1365/1876 [00:42<00:15, 32.31it/s, loss=0.034, v_num=5]\n",
      "Epoch 4:  73%|███████▎  | 1378/1876 [00:42<00:15, 32.52it/s, loss=0.034, v_num=5]\n",
      "Validating:  47%|████▋     | 441/938 [00:07<00:05, 98.45it/s]\u001b[A\n",
      "Epoch 4:  74%|███████▍  | 1391/1876 [00:42<00:14, 32.73it/s, loss=0.034, v_num=5]\n",
      "Epoch 4:  75%|███████▍  | 1404/1876 [00:42<00:14, 32.94it/s, loss=0.034, v_num=5]\n",
      "Epoch 4:  76%|███████▌  | 1417/1876 [00:42<00:13, 33.14it/s, loss=0.034, v_num=5]\n",
      "Epoch 4:  76%|███████▌  | 1430/1876 [00:42<00:13, 33.35it/s, loss=0.034, v_num=5]\n",
      "Epoch 4:  77%|███████▋  | 1443/1876 [00:43<00:12, 33.55it/s, loss=0.034, v_num=5]\n",
      "Validating:  54%|█████▍    | 507/938 [00:08<00:04, 101.99it/s]\u001b[A\n",
      "Epoch 4:  78%|███████▊  | 1456/1876 [00:43<00:12, 33.75it/s, loss=0.034, v_num=5]\n",
      "Epoch 4:  78%|███████▊  | 1469/1876 [00:43<00:11, 33.94it/s, loss=0.034, v_num=5]\n",
      "Epoch 4:  79%|███████▉  | 1482/1876 [00:43<00:11, 34.13it/s, loss=0.034, v_num=5]\n",
      "Epoch 4:  80%|███████▉  | 1495/1876 [00:43<00:11, 34.32it/s, loss=0.034, v_num=5]\n",
      "Epoch 4:  80%|████████  | 1508/1876 [00:43<00:10, 34.52it/s, loss=0.034, v_num=5]\n",
      "Validating:  61%|██████    | 571/938 [00:08<00:03, 96.83it/s]\u001b[A\n",
      "Epoch 4:  81%|████████  | 1521/1876 [00:43<00:10, 34.70it/s, loss=0.034, v_num=5]\n",
      "Epoch 4:  82%|████████▏ | 1534/1876 [00:43<00:09, 34.90it/s, loss=0.034, v_num=5]\n",
      "Epoch 4:  82%|████████▏ | 1547/1876 [00:44<00:09, 35.08it/s, loss=0.034, v_num=5]\n",
      "Validating:  65%|██████▌   | 611/938 [00:09<00:03, 93.69it/s]\u001b[A\n",
      "Epoch 4:  83%|████████▎ | 1560/1876 [00:44<00:08, 35.25it/s, loss=0.034, v_num=5]\n",
      "Epoch 4:  84%|████████▍ | 1573/1876 [00:44<00:08, 35.43it/s, loss=0.034, v_num=5]\n",
      "Epoch 4:  85%|████████▍ | 1586/1876 [00:44<00:08, 35.61it/s, loss=0.034, v_num=5]\n",
      "Validating:  69%|██████▉   | 651/938 [00:09<00:03, 92.77it/s]\u001b[A\n",
      "Epoch 4:  85%|████████▌ | 1599/1876 [00:44<00:07, 35.80it/s, loss=0.034, v_num=5]\n",
      "Epoch 4:  86%|████████▌ | 1612/1876 [00:44<00:07, 35.97it/s, loss=0.034, v_num=5]\n",
      "Epoch 4:  87%|████████▋ | 1625/1876 [00:44<00:06, 36.16it/s, loss=0.034, v_num=5]\n",
      "Epoch 4:  87%|████████▋ | 1638/1876 [00:45<00:06, 36.34it/s, loss=0.034, v_num=5]\n",
      "Validating:  75%|███████▍  | 702/938 [00:10<00:02, 96.65it/s]\u001b[A\n",
      "Epoch 4:  88%|████████▊ | 1651/1876 [00:45<00:06, 36.50it/s, loss=0.034, v_num=5]\n",
      "Epoch 4:  89%|████████▊ | 1664/1876 [00:45<00:05, 36.69it/s, loss=0.034, v_num=5]\n",
      "Epoch 4:  89%|████████▉ | 1677/1876 [00:45<00:05, 36.88it/s, loss=0.034, v_num=5]\n",
      "Epoch 4:  90%|█████████ | 1690/1876 [00:45<00:05, 37.05it/s, loss=0.034, v_num=5]\n",
      "Epoch 4:  91%|█████████ | 1703/1876 [00:45<00:04, 37.24it/s, loss=0.034, v_num=5]\n",
      "Validating:  82%|████████▏ | 766/938 [00:10<00:01, 99.76it/s]\u001b[A\n",
      "Epoch 4:  91%|█████████▏| 1716/1876 [00:45<00:04, 37.41it/s, loss=0.034, v_num=5]\n",
      "Epoch 4:  92%|█████████▏| 1729/1876 [00:45<00:03, 37.60it/s, loss=0.034, v_num=5]\n",
      "Epoch 4:  93%|█████████▎| 1742/1876 [00:46<00:03, 37.77it/s, loss=0.034, v_num=5]\n",
      "Epoch 4:  94%|█████████▎| 1755/1876 [00:46<00:03, 37.94it/s, loss=0.034, v_num=5]\n",
      "Epoch 4:  94%|█████████▍| 1768/1876 [00:46<00:02, 38.12it/s, loss=0.034, v_num=5]\n",
      "Validating:  89%|████████▊ | 832/938 [00:11<00:01, 99.87it/s]\u001b[A\n",
      "Epoch 4:  95%|█████████▍| 1781/1876 [00:46<00:02, 38.29it/s, loss=0.034, v_num=5]\n",
      "Epoch 4:  96%|█████████▌| 1794/1876 [00:46<00:02, 38.47it/s, loss=0.034, v_num=5]\n",
      "Epoch 4:  96%|█████████▋| 1807/1876 [00:46<00:01, 38.64it/s, loss=0.034, v_num=5]\n",
      "Epoch 4:  97%|█████████▋| 1820/1876 [00:46<00:01, 38.81it/s, loss=0.034, v_num=5]\n",
      "Epoch 4:  98%|█████████▊| 1833/1876 [00:47<00:01, 38.98it/s, loss=0.034, v_num=5]\n",
      "Validating:  96%|█████████▌| 897/938 [00:12<00:00, 99.02it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 1846/1876 [00:47<00:00, 39.14it/s, loss=0.034, v_num=5]\n",
      "Epoch 4:  99%|█████████▉| 1859/1876 [00:47<00:00, 39.31it/s, loss=0.034, v_num=5]\n",
      "Epoch 4: 100%|█████████▉| 1872/1876 [00:47<00:00, 39.47it/s, loss=0.034, v_num=5]\n",
      "Epoch 4: 100%|██████████| 1876/1876 [00:47<00:00, 39.48it/s, loss=0.034, v_num=5]\n",
      "Epoch 4: 100%|██████████| 1876/1876 [00:47<00:00, 39.48it/s, loss=0.034, v_num=5]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "model = RNN_LSTM(input_size, hidden_size, num_layers, num_classes)   \n",
    "# most basic trainer, uses good defaults (1 gpu)\n",
    "trainer = pl.Trainer(gpus = 1,max_epochs=5)    \n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Testing:  99%|█████████▉| 929/938 [00:08<00:00, 107.18it/s]--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_loss': tensor(0.0168, device='cuda:0')}\n",
      "--------------------------------------------------------------------------------\n",
      "Testing: 100%|██████████| 938/938 [00:08<00:00, 105.49it/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'test_loss': 0.016790278255939484}]"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}